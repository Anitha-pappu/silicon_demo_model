{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling tutorial\n",
    "\n",
    "In this notebook we'll walk through the main functions of the `modeling` package. For this tutorial, we'll use a preprocessed subset of a Kaggle dataset you can find [here](https://www.kaggle.com/datasets/edumagalhaes/quality-prediction-in-a-mining-process). The goal of the dataset is to predict the output silica concentration of a [floation](https://en.wikipedia.org/wiki/Froth_flotation) process at an iron mine. \n",
    "\n",
    "Though we use a tag dictionary in this example, most functions can be used without one. We'll highlight these features below.\n",
    "\n",
    "Of course, this notebook assumes you have a cleaned dataset.\n",
    "\n",
    "Currently, the model performance reporting in `modeling` only works for regression problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, we'll read in our datasets. For this problem, we'll read in the data and a simple tag dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:02:40.430374Z",
     "start_time": "2023-12-13T16:02:40.384438Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:02:40.443470Z",
     "start_time": "2023-12-13T16:02:40.433769Z"
    }
   },
   "outputs": [],
   "source": [
    "# Resolve path when used in a usecase project\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, str(Path(\"../../\").resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:02:44.417073Z",
     "start_time": "2023-12-13T16:02:40.447463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "from modeling.datasets import get_sample_model_input_data, get_sample_tag_dict\n",
    "\n",
    "df = get_sample_model_input_data()\n",
    "tag_dict = get_sample_tag_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:02:44.471695Z",
     "start_time": "2023-12-13T16:02:44.420517Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_flow01</th>\n",
       "      <th>air_flow02</th>\n",
       "      <th>air_flow03</th>\n",
       "      <th>air_flow04</th>\n",
       "      <th>air_flow05</th>\n",
       "      <th>air_flow06</th>\n",
       "      <th>air_flow07</th>\n",
       "      <th>amina_flow</th>\n",
       "      <th>column_level01</th>\n",
       "      <th>column_level02</th>\n",
       "      <th>...</th>\n",
       "      <th>ore_pulp_flow</th>\n",
       "      <th>ore_pulp_ph</th>\n",
       "      <th>silica_conc</th>\n",
       "      <th>silica_feed</th>\n",
       "      <th>starch_flow</th>\n",
       "      <th>iron_minus_silica</th>\n",
       "      <th>feed_diff_divide_silica</th>\n",
       "      <th>total_column_level</th>\n",
       "      <th>total_air_flow</th>\n",
       "      <th>silica_conc_lagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1368.00</td>\n",
       "      <td>1368.00</td>\n",
       "      <td>1368.00</td>\n",
       "      <td>1368.00</td>\n",
       "      <td>1368.00</td>\n",
       "      <td>1368.00</td>\n",
       "      <td>1368.00</td>\n",
       "      <td>1473.00</td>\n",
       "      <td>1368.00</td>\n",
       "      <td>1368.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1368.00</td>\n",
       "      <td>1368.00</td>\n",
       "      <td>1368.00</td>\n",
       "      <td>1368.00</td>\n",
       "      <td>1473.00</td>\n",
       "      <td>1368.00</td>\n",
       "      <td>1368.00</td>\n",
       "      <td>1473.00</td>\n",
       "      <td>1473.00</td>\n",
       "      <td>1367.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>280.40</td>\n",
       "      <td>277.26</td>\n",
       "      <td>281.19</td>\n",
       "      <td>298.99</td>\n",
       "      <td>299.02</td>\n",
       "      <td>286.84</td>\n",
       "      <td>287.05</td>\n",
       "      <td>480.04</td>\n",
       "      <td>518.90</td>\n",
       "      <td>522.32</td>\n",
       "      <td>...</td>\n",
       "      <td>397.35</td>\n",
       "      <td>9.77</td>\n",
       "      <td>12.81</td>\n",
       "      <td>14.64</td>\n",
       "      <td>2947.89</td>\n",
       "      <td>41.66</td>\n",
       "      <td>4.10</td>\n",
       "      <td>3033.23</td>\n",
       "      <td>1867.43</td>\n",
       "      <td>2.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28.00</td>\n",
       "      <td>28.43</td>\n",
       "      <td>27.60</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.21</td>\n",
       "      <td>22.42</td>\n",
       "      <td>22.08</td>\n",
       "      <td>77.78</td>\n",
       "      <td>114.37</td>\n",
       "      <td>110.31</td>\n",
       "      <td>...</td>\n",
       "      <td>7.40</td>\n",
       "      <td>0.34</td>\n",
       "      <td>3.24</td>\n",
       "      <td>6.62</td>\n",
       "      <td>708.08</td>\n",
       "      <td>11.59</td>\n",
       "      <td>3.19</td>\n",
       "      <td>967.32</td>\n",
       "      <td>530.16</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>200.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>293.46</td>\n",
       "      <td>287.21</td>\n",
       "      <td>200.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>300.00</td>\n",
       "      <td>303.84</td>\n",
       "      <td>228.22</td>\n",
       "      <td>...</td>\n",
       "      <td>378.32</td>\n",
       "      <td>9.00</td>\n",
       "      <td>8.15</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>250.09</td>\n",
       "      <td>250.09</td>\n",
       "      <td>250.08</td>\n",
       "      <td>299.70</td>\n",
       "      <td>299.75</td>\n",
       "      <td>273.89</td>\n",
       "      <td>279.21</td>\n",
       "      <td>422.58</td>\n",
       "      <td>428.30</td>\n",
       "      <td>449.56</td>\n",
       "      <td>...</td>\n",
       "      <td>399.28</td>\n",
       "      <td>9.55</td>\n",
       "      <td>10.30</td>\n",
       "      <td>9.18</td>\n",
       "      <td>2296.32</td>\n",
       "      <td>32.97</td>\n",
       "      <td>1.69</td>\n",
       "      <td>2771.38</td>\n",
       "      <td>1846.63</td>\n",
       "      <td>1.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>299.85</td>\n",
       "      <td>299.54</td>\n",
       "      <td>299.90</td>\n",
       "      <td>299.91</td>\n",
       "      <td>299.89</td>\n",
       "      <td>299.83</td>\n",
       "      <td>299.81</td>\n",
       "      <td>491.99</td>\n",
       "      <td>499.89</td>\n",
       "      <td>500.00</td>\n",
       "      <td>...</td>\n",
       "      <td>399.91</td>\n",
       "      <td>9.80</td>\n",
       "      <td>12.25</td>\n",
       "      <td>14.18</td>\n",
       "      <td>2925.19</td>\n",
       "      <td>41.91</td>\n",
       "      <td>2.95</td>\n",
       "      <td>3124.30</td>\n",
       "      <td>2084.03</td>\n",
       "      <td>2.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>299.92</td>\n",
       "      <td>299.86</td>\n",
       "      <td>299.93</td>\n",
       "      <td>299.95</td>\n",
       "      <td>299.97</td>\n",
       "      <td>299.94</td>\n",
       "      <td>299.94</td>\n",
       "      <td>540.93</td>\n",
       "      <td>599.80</td>\n",
       "      <td>599.38</td>\n",
       "      <td>...</td>\n",
       "      <td>400.34</td>\n",
       "      <td>10.01</td>\n",
       "      <td>14.50</td>\n",
       "      <td>19.58</td>\n",
       "      <td>3442.27</td>\n",
       "      <td>50.50</td>\n",
       "      <td>5.48</td>\n",
       "      <td>3548.30</td>\n",
       "      <td>2099.05</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>300.00</td>\n",
       "      <td>300.00</td>\n",
       "      <td>300.00</td>\n",
       "      <td>300.00</td>\n",
       "      <td>300.00</td>\n",
       "      <td>300.00</td>\n",
       "      <td>300.00</td>\n",
       "      <td>698.68</td>\n",
       "      <td>800.00</td>\n",
       "      <td>800.00</td>\n",
       "      <td>...</td>\n",
       "      <td>410.00</td>\n",
       "      <td>10.77</td>\n",
       "      <td>27.77</td>\n",
       "      <td>30.00</td>\n",
       "      <td>5943.95</td>\n",
       "      <td>63.00</td>\n",
       "      <td>31.50</td>\n",
       "      <td>5094.78</td>\n",
       "      <td>2099.91</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       air_flow01  air_flow02  air_flow03  air_flow04  air_flow05  air_flow06  \\\n",
       "count     1368.00     1368.00     1368.00     1368.00     1368.00     1368.00   \n",
       "mean       280.40      277.26      281.19      298.99      299.02      286.84   \n",
       "std         28.00       28.43       27.60        1.80        2.21       22.42   \n",
       "min        200.00      200.00      200.00      293.46      287.21      200.00   \n",
       "25%        250.09      250.09      250.08      299.70      299.75      273.89   \n",
       "50%        299.85      299.54      299.90      299.91      299.89      299.83   \n",
       "75%        299.92      299.86      299.93      299.95      299.97      299.94   \n",
       "max        300.00      300.00      300.00      300.00      300.00      300.00   \n",
       "\n",
       "       air_flow07  amina_flow  column_level01  column_level02  ...  \\\n",
       "count     1368.00     1473.00         1368.00         1368.00  ...   \n",
       "mean       287.05      480.04          518.90          522.32  ...   \n",
       "std         22.08       77.78          114.37          110.31  ...   \n",
       "min        200.00      300.00          303.84          228.22  ...   \n",
       "25%        279.21      422.58          428.30          449.56  ...   \n",
       "50%        299.81      491.99          499.89          500.00  ...   \n",
       "75%        299.94      540.93          599.80          599.38  ...   \n",
       "max        300.00      698.68          800.00          800.00  ...   \n",
       "\n",
       "       ore_pulp_flow  ore_pulp_ph  silica_conc  silica_feed  starch_flow  \\\n",
       "count        1368.00      1368.00      1368.00      1368.00      1473.00   \n",
       "mean          397.35         9.77        12.81        14.64      2947.89   \n",
       "std             7.40         0.34         3.24         6.62       708.08   \n",
       "min           378.32         9.00         8.15         2.00      2000.00   \n",
       "25%           399.28         9.55        10.30         9.18      2296.32   \n",
       "50%           399.91         9.80        12.25        14.18      2925.19   \n",
       "75%           400.34        10.01        14.50        19.58      3442.27   \n",
       "max           410.00        10.77        27.77        30.00      5943.95   \n",
       "\n",
       "       iron_minus_silica  feed_diff_divide_silica  total_column_level  \\\n",
       "count            1368.00                  1368.00             1473.00   \n",
       "mean               41.66                     4.10             3033.23   \n",
       "std                11.59                     3.19              967.32   \n",
       "min                15.00                     0.50                0.00   \n",
       "25%                32.97                     1.69             2771.38   \n",
       "50%                41.91                     2.95             3124.30   \n",
       "75%                50.50                     5.48             3548.30   \n",
       "max                63.00                    31.50             5094.78   \n",
       "\n",
       "       total_air_flow  silica_conc_lagged  \n",
       "count         1473.00             1367.00  \n",
       "mean          1867.43                2.32  \n",
       "std            530.16                1.01  \n",
       "min              0.00                1.00  \n",
       "25%           1846.63                1.55  \n",
       "50%           2084.03                2.05  \n",
       "75%           2099.05                2.91  \n",
       "max           2099.91                5.00  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our tag dictionary, we're interested in three columns:\n",
    "\n",
    "- The tag: the literal column name in our dataset.\n",
    "- The tag type: what the tag represents in the process. Here we're only concerned with `\"control\"`, `\"input\"`, and \"`output`\" tags. \n",
    "- The feature indicator column: this boolean column is `True` for tags that are features in the model we'd like to build. Note that we can have more than one of these columns in the tag dictionary.\n",
    "\n",
    "This last column is named `td_features_column` here and in all `modeling` function arguments. See more below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Note</b>\n",
    "\n",
    "Remember, we are modeling dependencies between physical properties of the process and the target, meaning that each feature name should represent very clear and human-readable phisical property, not a copy-pasted tag identifier.\r\n",
    "\r\n",
    "* An example of a good feature name is `pump_pressure_kPa | H105`. It represents the **human-readable physical property of the process**, unit of measurement, and the reference to the original tag this physical property is calculated based on. If the preprocessing recipe or formula for this specific feature changes, a new feature called `pump_pressure_kPa | H105` will be created, while `pump_pressure_kPa | H105` will still exist and usthean old recipe othe a old formula. \r\n",
    "\r\n",
    "* An example of a bad feature name is `ZO.RHONH955.H105.SP` because it is not human-readable, and it is hard to tie the tag identifier with its physical meaning. Additionally, full tag identifiers are never uby SMEs in day-to-day communications.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:02:44.479674Z",
     "start_time": "2023-12-13T16:02:44.476798Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>tag_type</th>\n",
       "      <th>silica_model_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iron_feed</td>\n",
       "      <td>input</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>silica_feed</td>\n",
       "      <td>input</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>starch_flow</td>\n",
       "      <td>control</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amina_flow</td>\n",
       "      <td>control</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ore_pulp_flow</td>\n",
       "      <td>control</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ore_pulp_ph</td>\n",
       "      <td>control</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ore_pulp_density</td>\n",
       "      <td>control</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>air_flow01</td>\n",
       "      <td>input</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>air_flow02</td>\n",
       "      <td>input</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>air_flow03</td>\n",
       "      <td>input</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>air_flow04</td>\n",
       "      <td>input</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>air_flow05</td>\n",
       "      <td>input</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>air_flow06</td>\n",
       "      <td>input</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>air_flow07</td>\n",
       "      <td>input</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>column_level01</td>\n",
       "      <td>input</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>column_level02</td>\n",
       "      <td>input</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>column_level03</td>\n",
       "      <td>input</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>column_level04</td>\n",
       "      <td>input</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>column_level05</td>\n",
       "      <td>input</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>column_level06</td>\n",
       "      <td>input</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>column_level07</td>\n",
       "      <td>input</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>iron_conc</td>\n",
       "      <td>input</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>silica_conc</td>\n",
       "      <td>output</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>total_air_flow</td>\n",
       "      <td>control</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>total_column_level</td>\n",
       "      <td>control</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>iron_minus_silica</td>\n",
       "      <td>input</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>feed_diff_divide_silica</td>\n",
       "      <td>input</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>silica_conc_lagged</td>\n",
       "      <td>input</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        tag tag_type silica_model_features\n",
       "0                 iron_feed    input                     Y\n",
       "1               silica_feed    input                     Y\n",
       "2               starch_flow  control                     Y\n",
       "3                amina_flow  control                     Y\n",
       "4             ore_pulp_flow  control                     Y\n",
       "5               ore_pulp_ph  control                     Y\n",
       "6          ore_pulp_density  control                     Y\n",
       "7                air_flow01    input                   NaN\n",
       "8                air_flow02    input                   NaN\n",
       "9                air_flow03    input                   NaN\n",
       "10               air_flow04    input                   NaN\n",
       "11               air_flow05    input                   NaN\n",
       "12               air_flow06    input                   NaN\n",
       "13               air_flow07    input                   NaN\n",
       "14           column_level01    input                   NaN\n",
       "15           column_level02    input                   NaN\n",
       "16           column_level03    input                   NaN\n",
       "17           column_level04    input                   NaN\n",
       "18           column_level05    input                   NaN\n",
       "19           column_level06    input                   NaN\n",
       "20           column_level07    input                   NaN\n",
       "21                iron_conc    input                   NaN\n",
       "22              silica_conc   output                   NaN\n",
       "23           total_air_flow  control                     Y\n",
       "24       total_column_level  control                     Y\n",
       "25        iron_minus_silica    input                   NaN\n",
       "26  feed_diff_divide_silica    input                     Y\n",
       "27       silica_conc_lagged    input                   NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_features_column = \"silica_model_features\"\n",
    "\n",
    "tag_dict.to_frame()[[\"tag\", \"tag_type\", td_features_column]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using td and `td_features_column` below, a list of feature names can be passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:02:44.517723Z",
     "start_time": "2023-12-13T16:02:44.481314Z"
    }
   },
   "outputs": [],
   "source": [
    "model_features = tag_dict.select(td_features_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first function we can use from `oai.modeling` is `drop_nan_rows`. This function simply drops nan rows for features and the target that we're including in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:02:44.518372Z",
     "start_time": "2023-12-13T16:02:44.498919Z"
    }
   },
   "outputs": [],
   "source": [
    "target_column = \"silica_conc\"\n",
    "datetime_column = \"timestamp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:02:44.543763Z",
     "start_time": "2023-12-13T16:02:44.501755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:modeling.utils:Dropping 105 rows with NaN values. Original sample size was 1473 and is now 1368.\n"
     ]
    }
   ],
   "source": [
    "from modeling.utils import drop_nan_rows\n",
    "\n",
    "df_dropna = drop_nan_rows(\n",
    "    df,\n",
    "    td=tag_dict,\n",
    "    td_features_column=td_features_column,\n",
    "    target_column=target_column,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Note</b>\n",
    "    \n",
    "> The idea of modeling in OptimusAI is to **learn joint dependencies** between features and target as accurately as possible, meaning the models we build are **descriptive**, not predictive.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial [we will build a SklearnPipeline](../../../../../../docs/build/apidoc/modeling/modeling.models.sklearn_pipeline.html#modeling.models.sklearn_pipeline.model.SklearnPipeline), which is a wrapper for `sklearn.pipeline.Pipeline`, however you are welcome to use [any other model from the list](../../../../../../docs/build/apidoc/modeling/modeling.models.sklearn_model.html) or [implement your own modeling logic](./model_base.ipynb#Create-a-custom-inheritor-of-ModelBase).\n",
    "\n",
    "The modeling procedure in modeling package consists of 4 major steps:\n",
    "\n",
    "1. initialize `ModelFactory` using the `create_model_factory` function\n",
    "2. produce model with `ModelFactory` using the `create_model` function\n",
    "3. split data on train and test datasets using the `create_splitter` and `split_data` functions\n",
    "4. tune hyperparameters using the `tune_model` function\n",
    "5. train model using the `train_model` function\n",
    "\n",
    "Modeling logic is encapsulated in the model classes and the functions, that we'll use in this section are mostly for pipelining purposes.\n",
    "\n",
    "Please see\n",
    "\n",
    "- [tutorial](./model_base.ipynb) on ModelBase to learn what that class is, what methods does it have, and how components interact with each other.\n",
    "- [tutorial](./splitter_base.ipynb) on SplitterBase to understand what splitter subpackage can offer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After executing this step, **you'll get a trained model instance and other entities needed for running model performance report**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `create_model_factory_from_tag_dict`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to initialize model factory. `create_model_factory` simply creates factory object using the `init_config`. Learn more about `init_config` structure in \n",
    "\n",
    "`ModelFactory` creates models based on the configuration representation. `Modelfactorys` are also required for model hyperparameters tuning. Learn about `model_init_config` structure for each of the builder classes in `ModelFactory` [tutorial](./model_base.ipynb) as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Note</b>\n",
    "    \n",
    "Each of the `ModelFactory` classes require its own structure of initialization config, which is described in API section.\n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:02:44.571235Z",
     "start_time": "2023-12-13T16:02:44.508375Z"
    }
   },
   "outputs": [],
   "source": [
    "from modeling import create_model_factory_from_tag_dict\n",
    "\n",
    "sklearn_pipeline_init_config = {\n",
    "    'estimator': {\n",
    "        'class_name': 'sklearn.linear_model.SGDRegressor',\n",
    "        'kwargs': {\n",
    "            'penalty': 'elasticnet', \n",
    "            'random_state': 123,\n",
    "        }\n",
    "    },\n",
    "    'transformers': [\n",
    "        {\n",
    "            'class_name': 'sklearn.preprocessing.StandardScaler',\n",
    "            'kwargs': {},\n",
    "            'name': 'standard_scaler',\n",
    "            'wrapper': 'preserve_columns',\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "sklearn_pipeline_factory = create_model_factory_from_tag_dict(\n",
    "    # Class type can be passed as well. See function API.\n",
    "    \"modeling.SklearnPipelineFactory\",\n",
    "    sklearn_pipeline_init_config,\n",
    "    tag_dict,\n",
    "    td_features_column,\n",
    "    target_column,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you don't use `TagDict` you can execute `modeling.create_model_factory` which does the same job, but require features provided manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `create_model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll create a model. This function calls factory's `.create()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:02:44.623305Z",
     "start_time": "2023-12-13T16:02:44.516058Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SklearnPipeline(estimator=Pipeline(steps=[('standard_scaler',\n",
       "                 SklearnTransform(transformer=StandardScaler())),\n",
       "                ('estimator',\n",
       "                 SGDRegressor(penalty='elasticnet', random_state=123))]), target=\"silica_conc\" ,features_in=['iron_feed', 'silica_feed', 'starch_flow', 'amina_flow', 'ore_pulp_flow', 'ore_pulp_ph', 'ore_pulp_density', 'total_air_flow', 'total_column_level', 'feed_diff_divide_silica'], features_out=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modeling import create_model\n",
    "\n",
    "sklearn_pipeline = create_model(sklearn_pipeline_factory)\n",
    "sklearn_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `split_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `modeling` module contains a few useful classes for splitting data on train and test datasets. We've demonstrated how to use those in the `splitters` [tutorial](./splitter_base.ipynb)\n",
    "\n",
    "Each of the classes have the same API defined by `SplitterBase` ([API](../../../../../../docs/build/apidoc/modeling/modeling.splitters.html#modeling.splitters.base_splitter.SplitterBase)). Call `.split` method on data to split on train and test datasets.\n",
    "\n",
    "We'll create a splitter instance using the function and then split the data by train and test like in the section above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:02:44.662471Z",
     "start_time": "2023-12-13T16:02:44.522416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:modeling.splitters._splitters.base_splitter:Length of data before splitting is 1368\n",
      "INFO:modeling.splitters._splitters.by_date_splitter:Splitting by datetime: 2017-08-30 23:00:00\n",
      "INFO:modeling.splitters._splitters.base_splitter:Length of the train data after splitting is 1287, length of the test data after splitting is 81.\n"
     ]
    }
   ],
   "source": [
    "from modeling import create_splitter, split_data\n",
    "\n",
    "split_datetime = \"2017-08-30 23:00:00\"\n",
    "\n",
    "splitter = create_splitter(\n",
    "    \"date\", \n",
    "    splitting_parameters={\n",
    "        \"datetime_column\": datetime_column,\n",
    "        \"split_datetime\": split_datetime,\n",
    "    },\n",
    ")\n",
    "train_data, test_data = split_data(df_dropna, splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tune_model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to tune model hyperparameters. This is an optional step which produces `BaseModel` instance with its' hyperparameters tuned.\n",
    "\n",
    "As usual, we'll make a function call, which initializes `ModelTuner` and calls `.tune()` method.\n",
    "\n",
    "`ModelTuner` tunes models based on the configuration specification. Learn about `model_tuner_config` structure for each of the tuner classes in `ModelBase` [tutorial](./model_base.ipynb) as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Note</b>\n",
    "    \n",
    "Each of the `ModelTuner` classes require its own structure of initialization config, which is described in API section.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:02:44.663256Z",
     "start_time": "2023-12-13T16:02:44.534240Z"
    }
   },
   "outputs": [],
   "source": [
    "sklearn_pipeline_tuner_config = {\n",
    "    'class_name': 'sklearn.model_selection.GridSearchCV',\n",
    "    'kwargs': {\n",
    "        'n_jobs': -1,\n",
    "        'refit': 'mae',\n",
    "        'param_grid': {\n",
    "            'estimator__alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
    "            'estimator__l1_ratio': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1]\n",
    "        },\n",
    "        'scoring': {\n",
    "            'mae': 'neg_mean_absolute_error',\n",
    "            'rmse': 'neg_root_mean_squared_error',\n",
    "            'r2': 'r2',\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:02:44.663857Z",
     "start_time": "2023-12-13T16:02:44.536810Z"
    }
   },
   "outputs": [],
   "source": [
    "from modeling import create_tuner, tune_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:02:47.911507Z",
     "start_time": "2023-12-13T16:02:44.543260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:modeling.models.sklearn_pipeline.model:`features_out` attribute is not specified. Setting `features_out` based on factual data.\n",
      "INFO:modeling.models.sklearn_pipeline.tuner:Initializing sklearn hyperparameters tuner...\n",
      "INFO:modeling.models.sklearn_pipeline.tuner:Tuning hyperparameters...\n"
     ]
    }
   ],
   "source": [
    "model_tuner = create_tuner(\n",
    "    sklearn_pipeline_factory,\n",
    "    model_tuner_type=\"modeling.SklearnPipelineTuner\",\n",
    "    tuner_config=sklearn_pipeline_tuner_config,\n",
    ")\n",
    "sklearn_pipeline = tune_model(\n",
    "    model_tuner=model_tuner, \n",
    "    data=train_data,\n",
    "    hyperparameters_config=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train_model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then model finally is getting trained. This function simply calls `BaseModel`'s `.fit()` method. For training and testing we'll use train_data and test_data that we split above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Note</b>\n",
    "    \n",
    "We're only using the train data for running final model training step. Test data is not concatenated and is not used in any way for training final version of the model. Instead, test data will be used for producing test metrics in the next section.\n",
    "    \n",
    "**This approach is used by default to ensure model is validated and the expected behavior is captured on the unseen and likely the latest available data, before model is used for the optimizing.**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:02:47.925853Z",
     "start_time": "2023-12-13T16:02:47.917063Z"
    }
   },
   "outputs": [],
   "source": [
    "from modeling import train_model\n",
    "\n",
    "sklearn_pipeline = train_model(sklearn_pipeline, train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Evaluating model performance\n",
    "\n",
    "These steps utilize trained model to extract predictions, metrics and feature importance using the provided data. \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Note</b>\n",
    "    \n",
    "Steps below are needed mostly for extracting predictions and metrics into the DataFrames for storing as an artifacts of the training procedure. We expect functions below to be used in pipelining tools, e.g. Kedro.\n",
    "\n",
    "</div>\n",
    "\n",
    "Updated model performance report in the `reporting` package does not utilize DataFrames produced my these functions unlike previous version of model performance report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `calculate_model_predictions`\n",
    "\n",
    "The first datasets needed by the model report are the train and test sets with model predictions appended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:02:47.940748Z",
     "start_time": "2023-12-13T16:02:47.922158Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.742889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.378801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.819613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.468984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.458713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_prediction\n",
       "0         12.742889\n",
       "1         13.378801\n",
       "2         12.819613\n",
       "3         12.468984\n",
       "4         11.458713"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modeling import calculate_model_predictions\n",
    "\n",
    "\n",
    "train_predictions = calculate_model_predictions(\n",
    "    train_data, sklearn_pipeline,\n",
    ")\n",
    "test_predictions = calculate_model_predictions(\n",
    "    test_data, sklearn_pipeline,\n",
    ")\n",
    "\n",
    "train_predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `calculate_metrics`\n",
    "\n",
    "Next, we'll need metric dataset provided by the `calculate_metrics` function.\n",
    "\n",
    "We can either use the datasets we just created, or the model to create the predictions again. Below, we use the datasets rather than doing another prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:02:47.966444Z",
     "start_time": "2023-12-13T16:02:47.939014Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 1.9282782055363596,\n",
       " 'rmse': 2.4244794086208996,\n",
       " 'mse': 5.878100402826748,\n",
       " 'mape': 0.14826119319371578,\n",
       " 'r_squared': 0.4873476180975649,\n",
       " 'var_score': 0.4873609075368811}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modeling import calculate_metrics\n",
    "\n",
    "train_metrics = calculate_metrics(\n",
    "    train_data, model=sklearn_pipeline,\n",
    ")\n",
    "test_metrics = calculate_metrics(\n",
    "    test_data, model=sklearn_pipeline,\n",
    ")\n",
    "\n",
    "test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `calculate_model_prediction_bounds`\n",
    "\n",
    "We can use the above metrics to create approximate confidence intervals for the predictions. These intervals can be useful for monitoring live model performance.\n",
    "\n",
    "In reality, we would use the model metrics on test set on new data to calculate the lower and upper bounds. Below we show an example using the test metrics and test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>actuals</th>\n",
       "      <th>predictions</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>upper_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>2017-08-30 23:00:00</td>\n",
       "      <td>15.023342</td>\n",
       "      <td>12.470228</td>\n",
       "      <td>7.718249</td>\n",
       "      <td>17.222208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>2017-08-31 02:00:00</td>\n",
       "      <td>14.987169</td>\n",
       "      <td>13.194360</td>\n",
       "      <td>8.442380</td>\n",
       "      <td>17.946339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>2017-08-31 05:00:00</td>\n",
       "      <td>14.170544</td>\n",
       "      <td>14.128286</td>\n",
       "      <td>9.376306</td>\n",
       "      <td>18.880265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>2017-08-31 08:00:00</td>\n",
       "      <td>10.170830</td>\n",
       "      <td>11.654594</td>\n",
       "      <td>6.902615</td>\n",
       "      <td>16.406574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>2017-08-31 11:00:00</td>\n",
       "      <td>11.712113</td>\n",
       "      <td>12.100266</td>\n",
       "      <td>7.348287</td>\n",
       "      <td>16.852246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp    actuals  predictions  lower_bound  upper_bound\n",
       "1392 2017-08-30 23:00:00  15.023342    12.470228     7.718249    17.222208\n",
       "1393 2017-08-31 02:00:00  14.987169    13.194360     8.442380    17.946339\n",
       "1394 2017-08-31 05:00:00  14.170544    14.128286     9.376306    18.880265\n",
       "1395 2017-08-31 08:00:00  10.170830    11.654594     6.902615    16.406574\n",
       "1396 2017-08-31 11:00:00  11.712113    12.100266     7.348287    16.852246"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modeling import calculate_model_prediction_bounds\n",
    "\n",
    "prediction_bounds = calculate_model_prediction_bounds(\n",
    "    data=test_data,\n",
    "    model=sklearn_pipeline,\n",
    "    model_metrics=test_metrics,\n",
    "    error_metric=\"rmse\",\n",
    "    error_multiplier = 1.96,\n",
    ")\n",
    "prediction_bounds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### `cross_validate`\n",
    "\n",
    "In addition to studying model performance on a single train-test split, it is a good practice to _cross validate_ its performance on multiple splits.\n",
    "\n",
    "`modeling` provides `cross_validate()` function that provides an intuitive API to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:02:48.015741Z",
     "start_time": "2023-12-13T16:02:47.952445Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:modeling.models._cross_validation:Cross-validating using: TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mae</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mape</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mse</th>\n",
       "      <th colspan=\"2\" halign=\"left\">r_squared</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rmse</th>\n",
       "      <th colspan=\"2\" halign=\"left\">var_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.69</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.27</td>\n",
       "      <td>4.76</td>\n",
       "      <td>11.61</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>2.18</td>\n",
       "      <td>3.41</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.76</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.23</td>\n",
       "      <td>5.22</td>\n",
       "      <td>9.89</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.28</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.96</td>\n",
       "      <td>2.49</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.22</td>\n",
       "      <td>6.34</td>\n",
       "      <td>8.72</td>\n",
       "      <td>0.44</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>2.52</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.44</td>\n",
       "      <td>-0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mae        mape         mse        r_squared        rmse        \\\n",
       "     train  test train  test train   test     train  test train  test   \n",
       "Fold                                                                    \n",
       "0     1.69  2.95  0.12  0.27  4.76  11.61      0.31 -0.10  2.18  3.41   \n",
       "1     1.76  2.65  0.13  0.23  5.22   9.89      0.51  0.14  2.28  3.14   \n",
       "2     1.96  2.49  0.16  0.22  6.34   8.72      0.44 -0.25  2.52  2.95   \n",
       "\n",
       "     var_score        \n",
       "         train  test  \n",
       "Fold                  \n",
       "0         0.31  0.33  \n",
       "1         0.51  0.18  \n",
       "2         0.44 -0.11  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modeling import cross_validate\n",
    "\n",
    "cv_strategy_config = {\n",
    "    \"class_name\": \"sklearn.model_selection.TimeSeriesSplit\",\n",
    "    \"kwargs\": {\n",
    "        \"n_splits\": 3,\n",
    "    },\n",
    "}\n",
    "\n",
    "cross_validation_metrics = cross_validate(\n",
    "    model=sklearn_pipeline,\n",
    "    data=train_data,\n",
    "    cv_strategy_config=cv_strategy_config,\n",
    ")\n",
    "cross_validation_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Via `cv_strategy_config` argument to this function, you can use a cross-validator of your choice (e.g. `ShuffleSplit`) and customize its parameters. The general recommendations are:\n",
    "\n",
    "* Explore model performance with **multiple splitting strategies** provided in `sklearn.model_selection`. `TimeSeriesSplit` and `ShuffleSplit` are a must in most cases.\n",
    "* Check **not only the average values** of metrics across folds, but also variation from fold to fold and difference between train and test values.\n",
    "* If you are using a **`Tuner`** that involves cross-validation, **re-use its CV strategy** for model performance as well.\n",
    "\n",
    "In the example above, we are using a `TimeSeriesSplit` strategy which is usually a good proxy of what accuracy to expect in production.\n",
    "[Here in the `sklearn` documentation](https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#visualize-cross-validation-indices-for-many-cv-objects) you can find visual examples of this and other available strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Additionally, you may be interested in exploring specific data slices behind each fold to see why metrics are different. This can be achieved by supplying argument `return_splits=True`, while it defaults to `False`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:02:48.141639Z",
     "start_time": "2023-12-13T16:02:48.004141Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:modeling.models._cross_validation:Cross-validating using: TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>air_flow01</th>\n",
       "      <th>air_flow02</th>\n",
       "      <th>air_flow03</th>\n",
       "      <th>air_flow04</th>\n",
       "      <th>air_flow05</th>\n",
       "      <th>air_flow06</th>\n",
       "      <th>air_flow07</th>\n",
       "      <th>amina_flow</th>\n",
       "      <th>column_level01</th>\n",
       "      <th>...</th>\n",
       "      <th>ore_pulp_flow</th>\n",
       "      <th>ore_pulp_ph</th>\n",
       "      <th>silica_conc</th>\n",
       "      <th>silica_feed</th>\n",
       "      <th>starch_flow</th>\n",
       "      <th>iron_minus_silica</th>\n",
       "      <th>feed_diff_divide_silica</th>\n",
       "      <th>total_column_level</th>\n",
       "      <th>total_air_flow</th>\n",
       "      <th>silica_conc_lagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>2017-05-02 14:00:00</td>\n",
       "      <td>299.923863</td>\n",
       "      <td>299.815867</td>\n",
       "      <td>299.991593</td>\n",
       "      <td>299.967524</td>\n",
       "      <td>299.936769</td>\n",
       "      <td>299.785333</td>\n",
       "      <td>299.987863</td>\n",
       "      <td>531.154194</td>\n",
       "      <td>462.590172</td>\n",
       "      <td>...</td>\n",
       "      <td>399.186259</td>\n",
       "      <td>9.395195</td>\n",
       "      <td>16.946918</td>\n",
       "      <td>20.836667</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>32.216667</td>\n",
       "      <td>1.546153</td>\n",
       "      <td>2879.716996</td>\n",
       "      <td>2099.408811</td>\n",
       "      <td>2.426667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>2017-05-02 17:00:00</td>\n",
       "      <td>299.158680</td>\n",
       "      <td>299.772339</td>\n",
       "      <td>299.771094</td>\n",
       "      <td>299.903250</td>\n",
       "      <td>299.938078</td>\n",
       "      <td>299.795719</td>\n",
       "      <td>299.968526</td>\n",
       "      <td>494.676863</td>\n",
       "      <td>451.185796</td>\n",
       "      <td>...</td>\n",
       "      <td>400.169934</td>\n",
       "      <td>9.320372</td>\n",
       "      <td>15.676978</td>\n",
       "      <td>19.990000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>32.930000</td>\n",
       "      <td>1.647324</td>\n",
       "      <td>2759.806224</td>\n",
       "      <td>2098.307685</td>\n",
       "      <td>3.473333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>2017-05-02 20:00:00</td>\n",
       "      <td>299.740215</td>\n",
       "      <td>299.944333</td>\n",
       "      <td>299.928565</td>\n",
       "      <td>299.928594</td>\n",
       "      <td>299.912035</td>\n",
       "      <td>299.640856</td>\n",
       "      <td>299.900798</td>\n",
       "      <td>516.819924</td>\n",
       "      <td>450.692141</td>\n",
       "      <td>...</td>\n",
       "      <td>400.296176</td>\n",
       "      <td>9.422287</td>\n",
       "      <td>13.138355</td>\n",
       "      <td>19.990000</td>\n",
       "      <td>2110.479007</td>\n",
       "      <td>32.930000</td>\n",
       "      <td>1.647324</td>\n",
       "      <td>2913.800158</td>\n",
       "      <td>2098.995396</td>\n",
       "      <td>3.688333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>2017-05-02 23:00:00</td>\n",
       "      <td>299.970343</td>\n",
       "      <td>299.699035</td>\n",
       "      <td>299.970652</td>\n",
       "      <td>299.917854</td>\n",
       "      <td>299.991417</td>\n",
       "      <td>299.726178</td>\n",
       "      <td>299.861983</td>\n",
       "      <td>507.627161</td>\n",
       "      <td>450.277143</td>\n",
       "      <td>...</td>\n",
       "      <td>399.477817</td>\n",
       "      <td>9.502582</td>\n",
       "      <td>13.928617</td>\n",
       "      <td>15.966667</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>39.416667</td>\n",
       "      <td>2.468685</td>\n",
       "      <td>2928.556098</td>\n",
       "      <td>2099.137461</td>\n",
       "      <td>1.913333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>2017-05-03 02:00:00</td>\n",
       "      <td>299.935894</td>\n",
       "      <td>299.909102</td>\n",
       "      <td>299.968813</td>\n",
       "      <td>299.897320</td>\n",
       "      <td>299.880098</td>\n",
       "      <td>299.984594</td>\n",
       "      <td>299.710052</td>\n",
       "      <td>553.140015</td>\n",
       "      <td>440.183637</td>\n",
       "      <td>...</td>\n",
       "      <td>400.489189</td>\n",
       "      <td>9.390444</td>\n",
       "      <td>16.486466</td>\n",
       "      <td>7.920000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>52.390000</td>\n",
       "      <td>6.614899</td>\n",
       "      <td>2893.950035</td>\n",
       "      <td>2099.285874</td>\n",
       "      <td>2.190000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              timestamp  air_flow01  air_flow02  air_flow03  air_flow04  \\\n",
       "429 2017-05-02 14:00:00  299.923863  299.815867  299.991593  299.967524   \n",
       "430 2017-05-02 17:00:00  299.158680  299.772339  299.771094  299.903250   \n",
       "431 2017-05-02 20:00:00  299.740215  299.944333  299.928565  299.928594   \n",
       "432 2017-05-02 23:00:00  299.970343  299.699035  299.970652  299.917854   \n",
       "433 2017-05-03 02:00:00  299.935894  299.909102  299.968813  299.897320   \n",
       "\n",
       "     air_flow05  air_flow06  air_flow07  amina_flow  column_level01  ...  \\\n",
       "429  299.936769  299.785333  299.987863  531.154194      462.590172  ...   \n",
       "430  299.938078  299.795719  299.968526  494.676863      451.185796  ...   \n",
       "431  299.912035  299.640856  299.900798  516.819924      450.692141  ...   \n",
       "432  299.991417  299.726178  299.861983  507.627161      450.277143  ...   \n",
       "433  299.880098  299.984594  299.710052  553.140015      440.183637  ...   \n",
       "\n",
       "     ore_pulp_flow  ore_pulp_ph  silica_conc  silica_feed  starch_flow  \\\n",
       "429     399.186259     9.395195    16.946918    20.836667  2000.000000   \n",
       "430     400.169934     9.320372    15.676978    19.990000  2000.000000   \n",
       "431     400.296176     9.422287    13.138355    19.990000  2110.479007   \n",
       "432     399.477817     9.502582    13.928617    15.966667  2000.000000   \n",
       "433     400.489189     9.390444    16.486466     7.920000  2000.000000   \n",
       "\n",
       "     iron_minus_silica  feed_diff_divide_silica  total_column_level  \\\n",
       "429          32.216667                 1.546153         2879.716996   \n",
       "430          32.930000                 1.647324         2759.806224   \n",
       "431          32.930000                 1.647324         2913.800158   \n",
       "432          39.416667                 2.468685         2928.556098   \n",
       "433          52.390000                 6.614899         2893.950035   \n",
       "\n",
       "     total_air_flow  silica_conc_lagged  \n",
       "429     2099.408811            2.426667  \n",
       "430     2098.307685            3.473333  \n",
       "431     2098.995396            3.688333  \n",
       "432     2099.137461            1.913333  \n",
       "433     2099.285874            2.190000  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation_metrics, cv_splits = cross_validate(\n",
    "    model=sklearn_pipeline,\n",
    "    data=train_data,\n",
    "    cv_strategy_config=cv_strategy_config,\n",
    "    return_splits=True,\n",
    ")\n",
    "\n",
    "# This is a mapping from integer fold indices to dictionaries with train and test data.\n",
    "cv_splits[0][\"test_data\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `calculate_feature_importance`\n",
    "\n",
    "Then, we'll get the feature importances. Function below will just call `.get_feature_importance` method of the model and store the results in the DataFrame.\n",
    "\n",
    "\n",
    "In the example below we're extracting feature importance from `SklearnPipeline`. In the default implementation it will try to access `feature_importance_` attribute of the model or, if it does not exist, `sklearn.inspection.permutation_importance` [will be used instead](https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html#sklearn.inspection.permutation_importance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:02:48.167018Z",
     "start_time": "2023-12-13T16:02:48.061014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:modeling.models.sklearn_pipeline.model:Estimator of type <class 'sklearn.linear_model._stochastic_gradient.SGDRegressor'> does not have `feature_importances_` using sklearn.inspection.permutation_importances instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ore_pulp_density</th>\n",
       "      <td>0.318981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_air_flow</th>\n",
       "      <td>0.156597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feed_diff_divide_silica</th>\n",
       "      <td>0.055192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starch_flow</th>\n",
       "      <td>0.027987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ore_pulp_ph</th>\n",
       "      <td>0.023104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_column_level</th>\n",
       "      <td>0.011798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amina_flow</th>\n",
       "      <td>0.003491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silica_feed</th>\n",
       "      <td>0.000695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iron_feed</th>\n",
       "      <td>-0.004983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ore_pulp_flow</th>\n",
       "      <td>-0.016836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         feature_importance\n",
       "feature_name                               \n",
       "ore_pulp_density                   0.318981\n",
       "total_air_flow                     0.156597\n",
       "feed_diff_divide_silica            0.055192\n",
       "starch_flow                        0.027987\n",
       "ore_pulp_ph                        0.023104\n",
       "total_column_level                 0.011798\n",
       "amina_flow                         0.003491\n",
       "silica_feed                        0.000695\n",
       "iron_feed                         -0.004983\n",
       "ore_pulp_flow                     -0.016836"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modeling import calculate_feature_importance\n",
    "\n",
    "importances = calculate_feature_importance(train_data, sklearn_pipeline)\n",
    "importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `calculate_shap_feature_importance`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll extract SHAP feature importance from the train data.\n",
    "`ModelBase.get_shap_feature_importance()` method is used and result is returned in the form of DataFrame.\n",
    "\n",
    "Note, that `ModelBase.get_shap_feature_importance()` will calculate shap importance for all the features provided in the input dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:02:52.415438Z",
     "start_time": "2023-12-13T16:02:48.138795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:modeling.models.sklearn_pipeline.model:`Using model-agnostic` <class 'shap.explainers._exact.ExactExplainer'>` to extract SHAP values... `shap` can't apply model-specific algorithms for <class 'modeling.models.sklearn_pipeline.model.SklearnPipeline'>. Consider switching to `SklearnModel` if computation time or quality don't fit your needs.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shap_feature_importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ore_pulp_density</th>\n",
       "      <td>0.889351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_air_flow</th>\n",
       "      <td>0.803316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feed_diff_divide_silica</th>\n",
       "      <td>0.538580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starch_flow</th>\n",
       "      <td>0.330423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ore_pulp_flow</th>\n",
       "      <td>0.242422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_column_level</th>\n",
       "      <td>0.239330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ore_pulp_ph</th>\n",
       "      <td>0.228754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iron_feed</th>\n",
       "      <td>0.185321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amina_flow</th>\n",
       "      <td>0.049499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silica_feed</th>\n",
       "      <td>0.007501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         shap_feature_importance\n",
       "feature_name                                    \n",
       "ore_pulp_density                        0.889351\n",
       "total_air_flow                          0.803316\n",
       "feed_diff_divide_silica                 0.538580\n",
       "starch_flow                             0.330423\n",
       "ore_pulp_flow                           0.242422\n",
       "total_column_level                      0.239330\n",
       "ore_pulp_ph                             0.228754\n",
       "iron_feed                               0.185321\n",
       "amina_flow                              0.049499\n",
       "silica_feed                             0.007501"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modeling import calculate_shap_feature_importance\n",
    "import numpy as np\n",
    "\n",
    "samples = train_data.loc[np.random.choice(train_data.index, 200)]\n",
    "shap_importances = calculate_shap_feature_importance(samples, sklearn_pipeline)\n",
    "shap_importances"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "325.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "9b80e060dd13f7a9e18ef80f709f6dc2c4300fdc15c8c06f1c38ea1fe551dc40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
