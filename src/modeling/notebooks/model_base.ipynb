{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Model classes user guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are model classes is OptimusAI?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model classes provide OAI-specific predictive modeling functionality and **define the unified API for regression models**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Note</b>\n",
    "\n",
    "`modeling` package only supports the OptimusAI related use cases, where models are used for modeling the dependencies, meaning that we treat models as descriptive, not predictive models.\n",
    "    \n",
    "This means that modeling functionality **is designed and tested for solving regression problems, and is not designed for classification problems**.\n",
    "    \n",
    "You still can try to use `modeling` package for classification problems at your own risk.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we use model classes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It separates modeling logic from the actual usage of the model. This principle leads to the following advantages:\n",
    "\n",
    "- **Code extensibility**: Modeling logic can be extended or modified using the inheritance mechanism.\n",
    "Model interface remains the same which means that other project components do not require changes if one `ModelBase`\n",
    "inheritor class used instead of another.\n",
    "- **Code usability**: Model related artifacts might be stored in a single model object as attributes. \n",
    "That simplifies model usage i.e. user doesn't need to think what features do this or that model has.    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as tp\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolve path when used in a usecase project\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, str(Path(\"../../\").resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "# Generation of data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "\n",
    "N_FEATURES = 3\n",
    "\n",
    "model_features = [f\"Feature_{i + 1}\" for i in range(N_FEATURES)]\n",
    "model_target = \"Target\"\n",
    "\n",
    "X, y = make_blobs(n_samples=1000, n_features=N_FEATURES, centers=100, random_state=0)\n",
    "features_data = pd.DataFrame(X, columns=model_features)\n",
    "useless_data = pd.DataFrame(np.random.randn(1000, 5), columns=[f\"Noise_{i + 1}\" for i in range(5)])\n",
    "target_vector = pd.DataFrame(y, columns=[model_target])\n",
    "\n",
    "master_data = pd.concat([features_data, useless_data, target_vector], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model classes overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ModelBase.drawio-3.svg](./_images/_ModelBase.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ModelBase`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ModelBase](../../../../../../docs/build/apidoc/modeling/modeling.models.sklearn_model.html#modeling.models.model_base.model.ModelBase) defines a required interface for other model inheritors. \n",
    "Inheritors must implement the [mandatory methods](../../../../../../docs/build/apidoc/modeling/modeling.models.sklearn_model.html#modeling.models.model_base.model.ModelBase.features_int) and might extend the functionality with additional methods or attributes.\n",
    "Pay attention on the difference between `features_in` and `features_out`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding the difference between `features_in` and `features_out`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "We assume that some data transformations might happen inside `.fit` or `.predict` methods. In order to distinguish the set of columns in the `DataFrame` that is expected for the input for `.fit` or `.predict` methods and set of the columns after potential transformations, we store those in a different properties: `features_in` and `features_out`.\n",
    "\n",
    "So, `features_in` represents set of columns before any transformations and data with this set of columns is expected to be passed into `fit` or `predict` methods.\n",
    "\n",
    "`features_out` represents set of columns after all potential transformations and data with `features_out` set of columns is passed into predictor.\n",
    "\n",
    "See diagram below.\n",
    "\n",
    "```\n",
    "                 ____________________                 _________\n",
    "  features_in   |                    |  features_out |         |\n",
    "------^-------- |  data_preparations |-------^-------|predictor|---\n",
    "                |____________________|               |_________|\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `SklearnModel`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SklearnModel](../../../../../../docs/build/apidoc/modeling/modeling.models.sklearn_model.html#modeling.models.sklearn_model.model.SklearnModel) is a wrapper for a scikit-learn compatible estimator.\n",
    "\n",
    "It requires an estimator, list of feature column names and target column names for initialization.\n",
    "\n",
    "Model training or predict procedures will use the provided feature list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/Documents/optimus/optimus_env/lib/python3.8/site-packages/shap/utils/_clustering.py:35: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _pt_shuffle_rec(i, indexes, index_mask, partition_tree, M, pos):\n",
      "/Users/admin/Documents/optimus/optimus_env/lib/python3.8/site-packages/shap/utils/_clustering.py:54: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def delta_minimization_order(all_masks, max_swap_size=100, num_passes=2):\n",
      "/Users/admin/Documents/optimus/optimus_env/lib/python3.8/site-packages/shap/utils/_clustering.py:63: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window(order, start, length):\n",
      "/Users/admin/Documents/optimus/optimus_env/lib/python3.8/site-packages/shap/utils/_clustering.py:69: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window_score_gain(masks, order, start, length):\n",
      "/Users/admin/Documents/optimus/optimus_env/lib/python3.8/site-packages/shap/utils/_clustering.py:77: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _mask_delta_score(m1, m2):\n",
      "/Users/admin/Documents/optimus/optimus_env/lib/python3.8/site-packages/shap/links.py:5: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def identity(x):\n",
      "/Users/admin/Documents/optimus/optimus_env/lib/python3.8/site-packages/shap/links.py:10: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _identity_inverse(x):\n",
      "/Users/admin/Documents/optimus/optimus_env/lib/python3.8/site-packages/shap/links.py:15: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def logit(x):\n",
      "/Users/admin/Documents/optimus/optimus_env/lib/python3.8/site-packages/shap/links.py:20: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _logit_inverse(x):\n",
      "/Users/admin/Documents/optimus/optimus_env/lib/python3.8/site-packages/shap/utils/_masked_model.py:363: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_single_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "/Users/admin/Documents/optimus/optimus_env/lib/python3.8/site-packages/shap/utils/_masked_model.py:385: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_multi_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "/Users/admin/Documents/optimus/optimus_env/lib/python3.8/site-packages/shap/utils/_masked_model.py:428: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _init_masks(cluster_matrix, M, indices_row_pos, indptr):\n",
      "/Users/admin/Documents/optimus/optimus_env/lib/python3.8/site-packages/shap/utils/_masked_model.py:439: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _rec_fill_masks(cluster_matrix, indices_row_pos, indptr, indices, M, ind):\n",
      "/Users/admin/Documents/optimus/optimus_env/lib/python3.8/site-packages/shap/maskers/_tabular.py:186: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _single_delta_mask(dind, masked_inputs, last_mask, data, x, noop_code):\n",
      "/Users/admin/Documents/optimus/optimus_env/lib/python3.8/site-packages/shap/maskers/_tabular.py:197: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _delta_masking(masks, x, curr_delta_inds, varying_rows_out,\n",
      "/Users/admin/Documents/optimus/optimus_env/lib/python3.8/site-packages/shap/maskers/_image.py:175: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _jit_build_partition_tree(xmin, xmax, ymin, ymax, zmin, zmax, total_ywidth, total_zwidth, M, clustering, q):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/Documents/optimus/optimus_env/lib/python3.8/site-packages/shap/explainers/_partition.py:676: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def lower_credit(i, value, M, values, clustering):\n",
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from modeling import SklearnModel\n",
    "from modeling.models.model_base import ProducesShapFeatureImportance\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "\n",
    "sklearn_estimator = RandomForestRegressor(random_state=0)\n",
    "oai_model = SklearnModel(\n",
    "    estimator=sklearn_estimator,\n",
    "    target=model_target,\n",
    "    features_in=model_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SklearnModel(estimator=RandomForestRegressor(random_state=0), target=\"Target\" ,features_in=['Feature_1', 'Feature_2', 'Feature_3'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model training\n",
    "\n",
    "oai_model.fit(master_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "\n",
    "predictions = oai_model.predict(master_data)  # Ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following columns are missing from the dataframe: {'Feature_1'}.\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation on wrong feature set raises at error\n",
    "\n",
    "try:\n",
    "    oai_model.predict(master_data.drop(columns=['Feature_1']))\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Feature_1': 0.32569159609566567,\n",
       " 'Feature_2': 0.38453370238535023,\n",
       " 'Feature_3': 0.28977470151898416}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature importance is available through the same model object\n",
    "\n",
    "oai_model.get_feature_importance(master_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:modeling.models.metrics_utils:MAPE was excluded from regression metrics since target contains zeros.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mae': 5.253819999999999,\n",
       " 'rmse': 7.2587107257418655,\n",
       " 'mse': 52.6888814,\n",
       " 'r_squared': 0.9367670190219022,\n",
       " 'var_score': 0.9367703192962497}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regression metrics are available through the same model object\n",
    "\n",
    "oai_model.evaluate_metrics(master_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Feature_1', 'Feature_2', 'Feature_3']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial features list is available through attribute\n",
    "\n",
    "oai_model.features_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Feature_1', 'Feature_2', 'Feature_3']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set of features after transformations is the same because no transformations happen in SklearnModel.\n",
    "\n",
    "oai_model.features_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Target'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model target is available though the same model object\n",
    "\n",
    "oai_model.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrapped estimator might be exported through the object property\n",
    "\n",
    "oai_model.estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using custom SHAP values calculation\n",
    "\n",
    "`SklearnModel` uses `shap.Explainer` to calculate SHAP values. By design it should be able to choose the right alogrithm to calculate SHAP values.\n",
    "\n",
    "In case you face any issues with SHAP values calculation, or you desire to use custom algorithm, then by design you're able to do so by reimplementing `_produce_shap_explanation` mathod:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function _produce_shap_explanation in module modeling.models.model_base.produces_shap_importances:\n",
      "\n",
      "_produce_shap_explanation(self, data: pandas.core.frame.DataFrame, **kwargs: Any) -> modeling.models.model_base.produces_shap_importances.ShapExplanation\n",
      "    Produce an instance of shap.Explanation\n",
      "    based on provided data for ``self._features_in`` feature set.\n",
      "    \n",
      "    Args:\n",
      "        data: data to calculate SHAP\n",
      "         values containing ``self._features_in`` feature set\n",
      "        **kwargs: additional keyword arguments that\n",
      "         are required for method implementation\n",
      "    \n",
      "    Returns:\n",
      "        `shap.Explanation` containing prediction base values and SHAP values\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ProducesShapFeatureImportance._produce_shap_explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "\n",
    "class SklearnModelWithExactShapValues(SklearnModel):\n",
    "    def _produce_shap_explanation(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        **kwargs: tp.Any,\n",
    "    ) -> shap.Explanation:\n",
    "        explainer = shap.Explainer(\n",
    "            model=self._estimator.predict,\n",
    "            masker=data[self._features_in],\n",
    "            algorithm=\"exact\",\n",
    "            **kwargs,\n",
    "        )\n",
    "        return explainer(data[self._features_in])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Feature_1': 6.506388888888888,\n",
       " 'Feature_2': 3.3582407407407406,\n",
       " 'Feature_3': 4.719814814814816}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SklearnModelWithExactShapValues(\n",
    "    estimator=RandomForestRegressor(random_state=0),\n",
    "    target=model_target,\n",
    "    features_in=model_features,\n",
    ").fit(master_data).get_shap_feature_importance(master_data.loc[:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `SklearnPipeline`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SklearnPipeline](../../../../../../docs/build/apidoc/modeling/modeling.models.sklearn_pipeline.html#modeling.models.sklearn_pipeline.model.SklearnPipeline) is a wrapper for a scikit-learn pipeline.\n",
    "\n",
    "It requires a scikit-learn Pipeline, list of feature column names and target column name.\n",
    "\n",
    "`SklearnPipeline` will check if features are present in the provided dataset before running the pipeline for training or evaluation.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Note</b>\n",
    "\n",
    "Wrapped `sklearn.pipeline.Pipeline` might not contain feature selecting step explicitly.\n",
    "Features passed as `features_in` will be used for feature selection inside `fit`, `predict` and `transform` methods.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "from modeling import SklearnPipeline\n",
    "from optimus_core import SkLearnSelector\n",
    "from sklearn.feature_selection import f_regression, SelectKBest\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Note</b>\n",
    "\n",
    "Use `optimus_core.transformer` package to keep column names in the transformed datasets.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "\n",
    "sklearn_pipeline = sklearn.pipeline.Pipeline([\n",
    "    (\"best_feature_selector\", SkLearnSelector(SelectKBest(k=2, score_func=f_regression))),\n",
    "    (\"estimator\", RandomForestRegressor(random_state=0)),\n",
    "])\n",
    "\n",
    "oai_pipeline = SklearnPipeline(\n",
    "    estimator=sklearn_pipeline,\n",
    "    target=model_target,\n",
    "    features_in=model_features,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:modeling.models.sklearn_pipeline.model:`features_out` attribute is not specified. Setting `features_out` based on factual data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SklearnPipeline(estimator=Pipeline(steps=[('best_feature_selector',\n",
       "                 SkLearnSelector(selector=SelectKBest(k=2,\n",
       "                                                      score_func=<function f_regression at 0x7f85aa0c90d0>))),\n",
       "                ('estimator', RandomForestRegressor(random_state=0))]), target=\"Target\" ,features_in=['Feature_1', 'Feature_2', 'Feature_3'], features_out=['Feature_1', 'Feature_3'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model training\n",
    "\n",
    "oai_pipeline.fit(master_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "\n",
    "predictions = oai_pipeline.predict(master_data)  # Ok\n",
    "transformed_data = oai_pipeline.transform(master_data) # Ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following columns are missing from the dataframe: {'Feature_1'}.\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation on wrong feature set raises at error\n",
    "\n",
    "try:\n",
    "    oai_pipeline.predict(master_data.drop(columns=['Feature_1']))\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Target'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model target is available though the same model object\n",
    "\n",
    "oai_pipeline.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Feature_1', 'Feature_2', 'Feature_3']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Required feature list is available through the same model object\n",
    "\n",
    "oai_pipeline.features_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Feature_1', 'Feature_3']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline has a dynamic feature selection step.\n",
    "# Estimator is effectively trained on a different set of features\n",
    "# rather than indicated in a model initialization step.\n",
    "# Set of features after internal transformations is\n",
    "# available through a `.features_out` attribute.\n",
    "\n",
    "oai_pipeline.features_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:modeling.models.metrics_utils:MAPE was excluded from regression metrics since target contains zeros.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mae': 8.148340000000001,\n",
       " 'rmse': 10.457837950551731,\n",
       " 'mse': 109.36637460000001,\n",
       " 'r_squared': 0.8687472252025202,\n",
       " 'var_score': 0.8687525420145215}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regression metrics are available through the same model object\n",
    "\n",
    "oai_pipeline.evaluate_metrics(master_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Note</b>\n",
    "\n",
    "Please note, that `get_pipeline()` will return a sklearn.pipeline.Pipeline with `SelectColumns` as a first step.\n",
    "This is required for backwards compatibility – other project components use `sklearn.pipeline.Pipeline` rather that this wrapper.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapped pipeline might be exported through the getter.\n",
    "# Note, that first step in the exported Pipeline will be feature selection step.\n",
    "\n",
    "select_features, *pipeline_steps = oai_pipeline.get_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectColumns(items=['Feature_1', 'Feature_2', 'Feature_3'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.get_feature_importance()` vs  `get_shap_feature_importance()` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.get_feature_importance()` returns mapping from ``features_out`` (feature set that is produced after all transformations step) to feature importance. This invariant is defined because most of the feature importance extraction technics utilize estimators and return importances for feature set used by estimator (which are `features_out`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Feature_1': 0.514334464700997, 'Feature_3': 0.4856655352990031}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature importance is available through the same model object\n",
    "\n",
    "oai_pipeline.get_feature_importance(master_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that `Feature_2` is not presented in the dict, since it was dropped by the pipeline and this feature is not in `features_out` set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike `.get_feature_importance()`, `get_shap_feature_importance()` calculates feature importance for `features_in` feature set. SHAP values for `features_in` can always be calculated, because model-agnostic algorithms are used.\n",
    "\n",
    "Note, that `get_shap_feature_importance()` methods is not required by `modeling.ModelBase` class. It is provided by `modeling.ProducesShapFeatureImportance` abstraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:modeling.models.sklearn_pipeline.model:`Using model-agnostic` <class 'shap.explainers._exact.Exact'>` to extract SHAP values... `shap` can't apply model-specific algorithms for <class 'modeling.models.sklearn_pipeline.model.SklearnPipeline'>. Consider switching to `SklearnModel` if computation time or quality don't fit your needs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exact explainer: 1001it [00:19, 27.03it/s]                                                                                                                                  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Feature_1': 9.885153949999982,\n",
       " 'Feature_2': 1.91668902971287e-15,\n",
       " 'Feature_3': 9.671310550000003}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oai_pipeline.get_shap_feature_importance(master_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that SHAP feature importance for `Feature_2` is close to zero which is valid since this column is not really used for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to wrap fitted `sklearn.sklearn.Pipeline` with `SklearnPipeline`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SklearnPipeline` allows you to wrap fitted `sklearn.sklearn.Pipeline`. In this case you might want to explicitly point out the `features_out` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on property:\n",
      "\n",
      "    Pipeline might perform any data transformations.\n",
      "    This property returns the list of columns that are\n",
      "    used by the last step of wrapped ``sklearn.pipeline.Pipeline``\n",
      "    as the input features.\n",
      "    \n",
      "    Returns:\n",
      "        Copy of a list of columns that are\n",
      "        used by the last step of the wrapped pipeline.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(SklearnPipeline.features_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what happens if `features_out` is still not specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize and train sklearn.pipeline.Pipeline \n",
    "\n",
    "fitted_sklearn_pipeline = sklearn.pipeline.Pipeline([\n",
    "    (\"best_feature_selector\", SkLearnSelector(SelectKBest(k=2, score_func=f_regression))),\n",
    "    (\"estimator\", RandomForestRegressor(random_state=0)),\n",
    "])\n",
    "\n",
    "fitted_sklearn_pipeline = fitted_sklearn_pipeline.fit(\n",
    "    master_data[model_features],\n",
    "    master_data[model_target],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap trained sklearn.pipeline.Pipeline with SklearnPipeline\n",
    "\n",
    "oai_fitted_pipeline = SklearnPipeline(\n",
    "    estimator=fitted_sklearn_pipeline, \n",
    "    target=model_target, \n",
    "    features_in=model_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:modeling.models.sklearn_pipeline.model:`features_out` property was not set during initialization and `features_out` assumed to be equal to `features_in`.\n",
      " Please run `.fit` to automatically fill `features_out` based on data or reinitialize object with `features_out` argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Feature_1', 'Feature_2', 'Feature_3']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oai_fitted_pipeline.features_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Note</b>\n",
    "\n",
    "If `features_out` property is not specified explicitly, it will be discovered and stored over the first run of the `fit`, `predict` or `transform` methods.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:modeling.models.sklearn_pipeline.model:`features_out` attribute is not specified. Setting `features_out` based on factual data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Feature_1', 'Feature_3']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oai_fitted_pipeline.fit(master_data).features_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otherwise `features_out` can be passed into `SklearnPipeline.__init__` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "oai_fitted_pipeline = SklearnPipeline(\n",
    "    estimator=fitted_sklearn_pipeline, \n",
    "    target=model_target, \n",
    "    features_in=model_features,\n",
    "    features_out=['Feature_1', 'Feature_3'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Feature_1', 'Feature_3']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oai_fitted_pipeline.features_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = oai_fitted_pipeline.transform(master_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case provided `features_out` don't match with the factual data, error will be raised:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "oai_fitted_pipeline = SklearnPipeline(\n",
    "    estimator=fitted_sklearn_pipeline, \n",
    "    target=model_target, \n",
    "    features_in=model_features,\n",
    "    features_out=['Feature_1', 'Feature_2'], # note, Feature_2 is passed instead of Feature_3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the data after transformation does not match with expected list of columns.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    oai_fitted_pipeline.fit(master_data)\n",
    "\n",
    "except RuntimeError as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `KerasModel`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`KerasModel` ([API](../../../../../../docs/build/apidoc/modeling/modeling.models.keras_model.html#modeling.load.keras_model.model.KerasModel)) is a wrapper for `tensorflow.keras.Model`, that provides the neural networks modeling functionality to OptimusAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 19:27:20.873187: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from modeling.models.keras_model import KerasModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 19:27:46.349271: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Model initialization\n",
    "\n",
    "\n",
    "keras_model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Normalization(axis=-1),\n",
    "        keras.layers.Dense(units=256, activation=\"relu\"),\n",
    "        keras.layers.Dense(units=256, activation=\"tanh\"),\n",
    "        keras.layers.Dense(units=1),\n",
    "    ]\n",
    ")\n",
    "keras_model.compile(\n",
    "    optimizer=\"Adam\",\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[\n",
    "        keras.metrics.MeanAbsoluteError(),\n",
    "        keras.metrics.MeanSquaredError(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "oai_keras_model = KerasModel(\n",
    "    keras_model,\n",
    "    target=model_target,\n",
    "    features_in=model_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25/25 [==============================] - 1s 14ms/step - loss: 2140.7803 - mean_absolute_error: 38.1526 - mean_squared_error: 2140.7803 - val_loss: 1697.7728 - val_mean_absolute_error: 33.5011 - val_mean_squared_error: 1697.7728\n",
      "Epoch 2/3\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1329.7122 - mean_absolute_error: 30.1440 - mean_squared_error: 1329.7122 - val_loss: 1313.0930 - val_mean_absolute_error: 29.6113 - val_mean_squared_error: 1313.0930\n",
      "Epoch 3/3\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1074.2166 - mean_absolute_error: 27.5087 - mean_squared_error: 1074.2166 - val_loss: 1113.1453 - val_mean_absolute_error: 27.5806 - val_mean_squared_error: 1113.1453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KerasModel(keras_model={\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 3], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"normalization_input\"}}, {\"class_name\": \"Normalization\", \"config\": {\"name\": \"normalization\", \"trainable\": true, \"dtype\": \"float32\", \"axis\": [-1], \"mean\": null, \"variance\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 256, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 256, \"activation\": \"tanh\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 1, \"activation\": \"linear\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.11.0\", \"backend\": \"tensorflow\"}, target=\"Target\" ,features_in=['Feature_1', 'Feature_2', 'Feature_3'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model training\n",
    "\n",
    "\n",
    "oai_keras_model.fit(master_data, verbose=1, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 979us/step\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "\n",
    "predictions = oai_keras_model.predict(master_data)  # Ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following columns are missing from the dataframe: {'Feature_1'}.\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation on wrong feature set raises at error\n",
    "\n",
    "try:\n",
    "    oai_model.predict(master_data.drop(columns=['Feature_1']))\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=[<tf.Tensor: shape=(1000, 3), dtype=float64, numpy=\n",
      "array([[-9.08690132, -7.73057335,  4.08447067],\n",
      "       [ 0.49930086,  1.97693428, -2.40335983],\n",
      "       [-9.28733163, -1.51038255, -2.34421839],\n",
      "       ...,\n",
      "       [ 1.30482576, -7.70650532,  7.85641301],\n",
      "       [ 2.25477659, -1.91329172,  2.24042181],\n",
      "       [ 1.15112095, -6.05816342, -7.72829074]])>]. Consider rewriting this model with the Functional API.\n",
      "INFO:modeling.models.keras_model.model:`Using `<class 'shap.explainers._deep.Deep'>` to extract SHAP values...\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=[<tf.Tensor 'shap_rAnD:0' shape=(2000, 3) dtype=float32>]. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras is no longer supported, please use tf.keras instead.\n",
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/admin/Documents/optimus/optimus_env/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=[<tf.Tensor: shape=(1000, 3), dtype=float64, numpy=\n",
      "array([[-9.08690132, -7.73057335,  4.08447067],\n",
      "       [ 0.49930086,  1.97693428, -2.40335983],\n",
      "       [-9.28733163, -1.51038255, -2.34421839],\n",
      "       ...,\n",
      "       [ 1.30482576, -7.70650532,  7.85641301],\n",
      "       [ 2.25477659, -1.91329172,  2.24042181],\n",
      "       [ 1.15112095, -6.05816342, -7.72829074]])>]. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Feature_1': 0.3824434297509803,\n",
       " 'Feature_2': 0.3306285804748425,\n",
       " 'Feature_3': 0.35688388971420976}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature importance is available through the same model object\n",
    "\n",
    "oai_keras_model.get_feature_importance(master_data, algorith=\"exact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step\n",
      "WARNING:modeling.models.metrics_utils:MAPE was excluded from regression metrics since target contains zeros.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mae': 26.93634753704071,\n",
       " 'rmse': 31.90876062089665,\n",
       " 'mse': 1018.1690043616849,\n",
       " 'r_squared': -0.22192499773379515,\n",
       " 'var_score': 0.011586289722970267}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regression metrics are available through the same model object\n",
    "\n",
    "oai_keras_model.evaluate_metrics(master_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Feature_1', 'Feature_2', 'Feature_3']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features list is available through the same model object\n",
    "\n",
    "oai_keras_model.features_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Target'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model target is available though the same model object\n",
    "\n",
    "oai_keras_model.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizatio  (None, 3)                7         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               1024      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,080\n",
      "Trainable params: 67,073\n",
      "Non-trainable params: 7\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Wrapped estimator might be exported through the object property\n",
    "\n",
    "oai_keras_model.keras_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a custom inheritor of ModelBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Note</b>\n",
    "\n",
    "We ship model classes, that support a minimal set of attributes and methods. Those models are domain-agnostic, and we expect that users will extend modeling classes with domain-specific methods and attributes for their individual use cases.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say you are building a linear model for a \n",
    "[set_point_optimization](../../../../../usecases/set_point_optimization/src/set_point_optimization/README.md) usecase, and you also want to\n",
    "\n",
    "- Use linear regression weights as feature importances \n",
    "- Keep additional set of features that plant operators can control\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be achieved by doing the following:\n",
    "\n",
    "1. Import `ModelBase` and create a class inheritor. \n",
    "2. Implement mandatory abstract methods. \n",
    "3. Extend class with additional methods, attributes and properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "from typing import Iterable, List, Any, Dict\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from modeling import SklearnModel\n",
    "from modeling.models.sklearn_model import attribute_check_is_fitted\n",
    "\n",
    "\n",
    "# Inherit from `SklearnModel` class as it already \n",
    "# implements some methods the way you want.\n",
    "class LinearModel(SklearnModel):\n",
    "    def __init__(\n",
    "            self,\n",
    "            estimator: LinearRegression,\n",
    "            target: str,\n",
    "            features_in: Iterable[str],\n",
    "            controls: Iterable[str],\n",
    "    ) -> None:\n",
    "        super().__init__(estimator, features_in, target)\n",
    "        self._estimator = estimator\n",
    "        # Save controlled features into a private attribute\n",
    "        self._controls: List[str] = list(controls)\n",
    "\n",
    "    # 1. Create a property for the `_controls` attribute.\n",
    "    # 2. Return a copy since list is a mutable data structure.\n",
    "    @property\n",
    "    def controls(self) -> List[str]:\n",
    "        return copy(self._controls)\n",
    "\n",
    "    # 1. Implement your custom feature importance logic.\n",
    "    # 2. Use `attribute_check_is_fitted` decorator to check \n",
    "    # whether estimator is fitted before method is called.\n",
    "    @attribute_check_is_fitted(\"_estimator\")\n",
    "    def get_feature_importance(\n",
    "            self, data: pd.DataFrame, **kwargs: Any\n",
    "    ) -> Dict[str, float]:\n",
    "        return dict(zip(self.features_in, self._estimator.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model using the `ModelFactoryBase`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we'll show how to build `ModelBase` instance using the `ModelFactoryBase` [(API)](../../../../../../docs/build/apidoc/modeling/modeling.models.model_base.html#modeling.models.model_base.model_base.ModelFactoryBase) from the hyperparameters' specification.\n",
    "\n",
    "1. ModelFactories might be useful when hyperparameters are specified in the YAML files.\n",
    "2. ModelFactories must be used for model initialization in order to perform hyperparameters tuning. We'll talk more regarding this in the `ModelTunerBase` section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the `ModelFactoryBase` inheritors build their own `ModelBase` instances. Below is the table mapping from Factories to models that they build:\n",
    "\n",
    "|`ModelFactoryBase`|action|`ModelBase`|\n",
    "|---|---|---|\n",
    "|`SklearnModelFactory`|builds|`SklearnModel`|\n",
    "|`SklearnPipelineFactory`|builds|`SklearnPipeline`|\n",
    "|`KerasModelFactory`|builds|`KerasModel`|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ModelFactoryBase` UML class diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ModelFactoryBase.drawio.svg](./_images/_ModelFactroryBase.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `SklearnModel` using the `SklearnModelFactory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling import SklearnModelFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to initialize `SklearnModelFactory` ([API](../../../../../../docs/build/apidoc/modeling/modeling.models.sklearn_model.html#modeling.models.sklearn_model.factory.SklearnModelFactory)), we need to provide a dictionary with the following structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SklearnModelFactory in module modeling.models.sklearn_model.factory:\n",
      "\n",
      "class SklearnModelFactory(modeling.models.model_base.model_base.ModelFactoryBase)\n",
      " |  SklearnModelFactory(model_init_config: Dict[str, Any], features_in: Iterable[str], target: str) -> None\n",
      " |  \n",
      " |  Factory class that allows creating\n",
      " |  ``SklearnModel`` instance based on the parametrization specified\n",
      " |  in ``model_init_config``.\n",
      " |  \n",
      " |  `model_init_config` structure should match ``SklearnModelInitConfig``::\n",
      " |  \n",
      " |      # Object specification for sklearn compatible estimator\n",
      " |      # matching the `ObjectInitConfig` structure.\n",
      " |      estimator:\n",
      " |        class_name: sklearn.linear_model.SGDRegressor\n",
      " |        kwargs:\n",
      " |          random_state: 123\n",
      " |          penalty: elasticnet\n",
      " |  \n",
      " |      # Target transform config\n",
      " |      # matching the `TargetTransformerInitConfig` structure.\n",
      " |      # Either transformer key should be filled,\n",
      " |      # or `func` and `inverse_func` keys should be filled.\n",
      " |      target_transformer:\n",
      " |        # Object specification for transformer\n",
      " |        # matching the `ObjectInitConfig` structure\n",
      " |        transformer: null\n",
      " |        # Path for the function to use as target transform\n",
      " |        func: numpy.log1p\n",
      " |        # Path for the function to use as a inverse target transform\n",
      " |        inverse_func: numpy.expm1\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SklearnModelFactory\n",
      " |      modeling.models.model_base.model_base.ModelFactoryBase\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, model_init_config: Dict[str, Any], features_in: Iterable[str], target: str) -> None\n",
      " |      Args:\n",
      " |          model_init_config: Model initialization config\n",
      " |           which follows structure above.\n",
      " |          features_in: Features column names\n",
      " |           to be used for model training and prediction\n",
      " |          target: Name of the column used in model training\n",
      " |  \n",
      " |  create(self) -> modeling.models.sklearn_model.model.SklearnModel\n",
      " |      Build ``SklearnModel`` instance using ``create_model_instance`` method\n",
      " |       and ``self.model_init_config``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          `SklearnModel` instance\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  create_model_instance(init_config: Dict[str, Any]) -> modeling.api.estimator.Estimator\n",
      " |      Make ``sklearn`` estimator using ``init_config``\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from modeling.models.model_base.model_base.ModelFactoryBase:\n",
      " |  \n",
      " |  __repr__(self) -> 'str'\n",
      " |      String representation for model factories.\n",
      " |      \n",
      " |      Notes:\n",
      " |          As per definition of `__repr__` we strive to return a string representation\n",
      " |           that would yield an object with the same value when passed to eval();\n",
      " |      \n",
      " |      Returns:\n",
      " |          String representation.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from modeling.models.model_base.model_base.ModelFactoryBase:\n",
      " |  \n",
      " |  from_tag_dict(model_init_config: 'tp.Dict[str, tp.Any]', tag_dict: 'api.SupportsTagDict', tag_dict_features_column: 'str', target: 'str') -> 'TModelFactory' from abc.ABCMeta\n",
      " |      Use this method to initialize ModelBuilder from the TagDict.\n",
      " |      It fetches model features and other information which potentially can be used\n",
      " |      for model initialization from the TagDict.\n",
      " |      \n",
      " |      Args:\n",
      " |          model_init_config: Model initialization config follows structure of\n",
      " |           ModelFactoryBase inheritor.\n",
      " |          tag_dict: Instance of TagDict with tag-level information\n",
      " |          tag_dict_features_column: Column name from TagDict to be used for\n",
      " |           identifying model features\n",
      " |          target: Column name to be used as model target\n",
      " |      \n",
      " |      Returns:\n",
      " |          ModelFactoryBase initialized instance\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from modeling.models.model_base.model_base.ModelFactoryBase:\n",
      " |  \n",
      " |  features_in\n",
      " |  \n",
      " |  model_init_config\n",
      " |  \n",
      " |  target\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from modeling.models.model_base.model_base.ModelFactoryBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(SklearnModelFactory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compose a python dictionary representing the proposed YAML file and use it to build a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_model_init_config = {\n",
    "    # Object specification for sklearn compatible estimator\n",
    "    # matching the `ObjectInitConfig` structure.\n",
    "    \"estimator\": {\n",
    "        \"class_name\": \"sklearn.linear_model.SGDRegressor\",\n",
    "        \"kwargs\": {\n",
    "            \"random_state\": 123,\n",
    "            \"penalty\": \"elasticnet\",\n",
    "      }\n",
    "    },\n",
    "    # Target transform config matching the `TargetTransformerInitConfig` structure.\n",
    "    # Either transformer key should be filled,\n",
    "    # or `func` and `inverse_func` keys should be filled.\n",
    "    \"target_transformer\": {\n",
    "      # Object specification for transformer\n",
    "      # matching the `ObjectInitConfig` structure\n",
    "        \"transformer\": None,\n",
    "      # Path for the function to use as target transform\n",
    "        \"func\": \"numpy.log1p\",\n",
    "      # Path for the function to use as an inverse target transform\n",
    "        \"inverse_func\": \"numpy.expm1\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_factory = SklearnModelFactory(\n",
    "    sklearn_model_init_config, \n",
    "    model_features,\n",
    "    model_target,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `.create()`method we build a `SklearnModel` instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SklearnModel(estimator=TransformedTargetRegressor(func=<ufunc 'log1p'>, inverse_func=<ufunc 'expm1'>,\n",
       "                           regressor=SGDRegressor(penalty='elasticnet',\n",
       "                                                  random_state=123)), target=\"Target\" ,features_in=['Feature_1', 'Feature_2', 'Feature_3'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oai_sklearn_model = sklearn_factory.create()\n",
    "oai_sklearn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you want to parameterize your scikit-learn based model and **only specify the parameters that you want**. We'll build a toy example below to demonstrate the way how it can be done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say you want to create a Factory for `RandomForestRegressor`, but the only parameter you want to specify is the number of trees in your ensemble.\n",
    "\n",
    "First, you'll need to inherit from the `SklearnModelFactory` class to redefine the `make_model_instance()` \n",
    "staticmethod. Note, that method interface must remain unchanged in order to make other methods work properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserDefinedRandomForestFactory(SklearnModelFactory):\n",
    "    @staticmethod\n",
    "    def create_model_instance(\n",
    "        init_config: tp.Dict[str, tp.Any]\n",
    "    ) -> sklearn.ensemble.RandomForestRegressor:\n",
    "        return RandomForestRegressor(\n",
    "            init_config[\"n_estimators\"], max_depth=12,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's create a dictionary that keeps number of trees there. You might want to collect any information in YAML files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_init_config = {\n",
    "    \"n_estimators\": 512,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_factory = UserDefinedRandomForestFactory(\n",
    "    random_forest_init_config,\n",
    "    model_features,\n",
    "    model_target,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SklearnModel(estimator=RandomForestRegressor(max_depth=12, n_estimators=512), target=\"Target\" ,features_in=['Feature_1', 'Feature_2', 'Feature_3'])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oai_random_forest_model = random_forest_factory.create()\n",
    "oai_random_forest_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `SklearnPipeline` using the `SklearnPipelineFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling import SklearnPipelineFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usage of `SklearnPipelineFactory` is very similar to `SklearnModelFactory`.\n",
    "\n",
    "In order to initialize `SklearnPipelineFactory` ([API](../../../../../../docs/build/apidoc/modeling/modeling.models.sklearn_pipeline.html#modeling.models.sklearn_pipeline.factory.SklearnPipelineFactory)), we need to provide a dictionary with the following structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SklearnPipelineFactory in module modeling.models.sklearn_pipeline.factory:\n",
      "\n",
      "class SklearnPipelineFactory(modeling.models.model_base.model_base.ModelFactoryBase)\n",
      " |  SklearnPipelineFactory(model_init_config: Dict[str, Any], features_in: Iterable[str], target: str) -> None\n",
      " |  \n",
      " |  Factory class that allows creating\n",
      " |  ``SklearnPipeline`` instance based on the parametrization specified\n",
      " |  in ``model_init_config``.\n",
      " |  \n",
      " |  Structure of ``model_init_config`` that matches ``SklearnPipelineInitConfig``::\n",
      " |  \n",
      " |      # Object specification for sklearn compatible estimator\n",
      " |      # matching the `ObjectInitConfig` structure.\n",
      " |      estimator:\n",
      " |        class_name: sklearn.linear_model.SGDRegressor\n",
      " |        kwargs:\n",
      " |          random_state: 123\n",
      " |          penalty: elasticnet\n",
      " |  \n",
      " |      # List of object specification for sklearn compatible transformer\n",
      " |      # matching the `TransformerInitConfig` structure.\n",
      " |      transformers:\n",
      " |        - class_name: sklearn.preprocessing.StandardScaler\n",
      " |          kwargs: {}\n",
      " |          # Name of the step in sklearn.sklearn.Pipeline\n",
      " |          name: standard_scaler\n",
      " |          # `sklearn` compatible transformer do not\n",
      " |          # preserve column names by default.\n",
      " |          # We wrap it with `SklearnTransform` or `SklearnSelector`\n",
      " |          # classes to keep column names during transformations.\n",
      " |          # Use flag options below to choose which wrapper to use:\n",
      " |          # `wrapper: select_columns` to wrap with `SkLearnSelector`\n",
      " |          # `wrapper: preserve_columns` to wrap with `SklearnTransform`\n",
      " |          # `wrapper: preserve_pandas` to wrap with\n",
      " |          #  `ColumnNamesAsNumbers` (default option)\n",
      " |          # `wrapper: null` to skip wrapping\n",
      " |          wrapper: preserve_columns\n",
      " |  \n",
      " |      # Target transform config matching the\n",
      " |      `TargetTransformerInitConfig` structure.\n",
      " |      # Either transformer key should be filled,\n",
      " |      # or `func` and `inverse_func` keys should be filled.\n",
      " |      target_transformer:\n",
      " |        # Object specification for transformer\n",
      " |        # matching the `ObjectInitConfig` structure\n",
      " |        transformer: null\n",
      " |        # Path for the function to use as target transform\n",
      " |        func: numpy.log1p\n",
      " |        # Path for the function to use as a inverse target transform\n",
      " |        inverse_func: numpy.expm1\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SklearnPipelineFactory\n",
      " |      modeling.models.model_base.model_base.ModelFactoryBase\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, model_init_config: Dict[str, Any], features_in: Iterable[str], target: str) -> None\n",
      " |      Args:\n",
      " |          model_init_config: Model initialization config\n",
      " |           which the structure shown above.\n",
      " |          features_in: Features column names\n",
      " |           to be used for model training and prediction\n",
      " |          target: Name of the column used in model training\n",
      " |  \n",
      " |  create(self) -> modeling.models.sklearn_pipeline.model.SklearnPipeline\n",
      " |      Build ``SklearnPipeline`` instance.\n",
      " |      \n",
      " |      Returns:\n",
      " |          ``SklearnPipeline`` instance\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  create_model_instance(init_config: modeling.models.sklearn_pipeline.factory.SklearnPipelineInitConfig) -> sklearn.pipeline.Pipeline\n",
      " |      Make ``sklearn.pipeline.Pipeline`` instance using ``init_config``\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from modeling.models.model_base.model_base.ModelFactoryBase:\n",
      " |  \n",
      " |  __repr__(self) -> 'str'\n",
      " |      String representation for model factories.\n",
      " |      \n",
      " |      Notes:\n",
      " |          As per definition of `__repr__` we strive to return a string representation\n",
      " |           that would yield an object with the same value when passed to eval();\n",
      " |      \n",
      " |      Returns:\n",
      " |          String representation.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from modeling.models.model_base.model_base.ModelFactoryBase:\n",
      " |  \n",
      " |  from_tag_dict(model_init_config: 'tp.Dict[str, tp.Any]', tag_dict: 'api.SupportsTagDict', tag_dict_features_column: 'str', target: 'str') -> 'TModelFactory' from abc.ABCMeta\n",
      " |      Use this method to initialize ModelBuilder from the TagDict.\n",
      " |      It fetches model features and other information which potentially can be used\n",
      " |      for model initialization from the TagDict.\n",
      " |      \n",
      " |      Args:\n",
      " |          model_init_config: Model initialization config follows structure of\n",
      " |           ModelFactoryBase inheritor.\n",
      " |          tag_dict: Instance of TagDict with tag-level information\n",
      " |          tag_dict_features_column: Column name from TagDict to be used for\n",
      " |           identifying model features\n",
      " |          target: Column name to be used as model target\n",
      " |      \n",
      " |      Returns:\n",
      " |          ModelFactoryBase initialized instance\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from modeling.models.model_base.model_base.ModelFactoryBase:\n",
      " |  \n",
      " |  features_in\n",
      " |  \n",
      " |  model_init_config\n",
      " |  \n",
      " |  target\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from modeling.models.model_base.model_base.ModelFactoryBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(SklearnPipelineFactory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `wrappers` for features transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SklearnPipelineFactory` uses the wrappers from `optimus_core.transformers` to preserve `pd.DataFrame` for the transformed data. The desired logic can be chosen with the parameter `\"wrapper\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Setting \"wrapper\": \"preserve_pandas\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Provided transformers can be wrapped with `optimus_core.transformers.ColumnNamesAsNumbers` that preserves `pd.DataFrame` type for the output dataset and sets the column names as a range from 0 to `len(columns_count) - 1`. **This is the default option.** This option should be used when it is not clear how transformed columns relate to the columns in the input dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sklearn_pipeline_init_config = {\n",
    "    # Object specification for sklearn compatible estimator\n",
    "    # matching the `ObjectInitConfig` structure.\n",
    "    \"estimator\": {\n",
    "        \"class_name\": \"sklearn.linear_model.SGDRegressor\",\n",
    "        \"kwargs\": {\n",
    "            \"random_state\": 123,\n",
    "            \"penalty\": \"elasticnet\",\n",
    "      },\n",
    "    },\n",
    "    \"transformers\": [\n",
    "        {\n",
    "            \"class_name\": \"sklearn.preprocessing.StandardScaler\",\n",
    "            \"kwargs\": {},\n",
    "            \"name\": \"standard_scaler\",\n",
    "            \"wrapper\": \"preserve_pandas\",\n",
    "        },\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sklearn_pipeline_factory = SklearnPipelineFactory(\n",
    "    sklearn_pipeline_init_config, \n",
    "    model_features,\n",
    "    model_target,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:modeling.models.sklearn_pipeline.model:`features_out` attribute is not specified. Setting `features_out` based on factual data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.525443</td>\n",
       "      <td>-1.258792</td>\n",
       "      <td>0.642563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.087617</td>\n",
       "      <td>0.389456</td>\n",
       "      <td>-0.497629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.559169</td>\n",
       "      <td>-0.202659</td>\n",
       "      <td>-0.487236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.457546</td>\n",
       "      <td>0.576085</td>\n",
       "      <td>-0.934979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.038254</td>\n",
       "      <td>0.082757</td>\n",
       "      <td>1.079463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0 -1.525443 -1.258792  0.642563\n",
       "1  0.087617  0.389456 -0.497629\n",
       "2 -1.559169 -0.202659 -0.487236\n",
       "3  1.457546  0.576085 -0.934979\n",
       "4  0.038254  0.082757  1.079463"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_pipeline = sklearn_pipeline_factory.create()\n",
    "transformed_data = sklearn_pipeline.fit(master_data).transform(master_data)\n",
    "transformed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Setting \"wrapper\": \"preserve_columns\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Provided transformers can be wrapped with `optimus_core.transformers.SklearnTransform` that preserves `pd.DataFrame` type for the output dataset and sets the column names equal to columns in the input data. This option should be used when transformer does not change either set of columns or order of the columns in the transformed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sklearn_pipeline_init_config[\"transformers\"][0] = {\n",
    "    \"class_name\": \"sklearn.preprocessing.StandardScaler\",\n",
    "    \"kwargs\": {},\n",
    "    \"name\": \"standard_scaler\",\n",
    "    \"wrapper\": \"preserve_columns\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:modeling.models.sklearn_pipeline.model:`features_out` attribute is not specified. Setting `features_out` based on factual data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.525443</td>\n",
       "      <td>-1.258792</td>\n",
       "      <td>0.642563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.087617</td>\n",
       "      <td>0.389456</td>\n",
       "      <td>-0.497629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.559169</td>\n",
       "      <td>-0.202659</td>\n",
       "      <td>-0.487236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.457546</td>\n",
       "      <td>0.576085</td>\n",
       "      <td>-0.934979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.038254</td>\n",
       "      <td>0.082757</td>\n",
       "      <td>1.079463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature_1  Feature_2  Feature_3\n",
       "0  -1.525443  -1.258792   0.642563\n",
       "1   0.087617   0.389456  -0.497629\n",
       "2  -1.559169  -0.202659  -0.487236\n",
       "3   1.457546   0.576085  -0.934979\n",
       "4   0.038254   0.082757   1.079463"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_pipeline = sklearn_pipeline_factory.create()\n",
    "transformed_data = sklearn_pipeline.fit(master_data).transform(master_data)\n",
    "transformed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Setting \"wrapper\": \"select_columns\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Provided transformers can be wrapped with `optimus_core.transformers.SkLearnSelector` that preserves `pd.DataFrame` type for the output dataset and picks the subset of columns for the transformed dataset from the input dataset. This option should be used when transformer performs the feature selection, and hence transformed set of columns will always be a subset of the inputs columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sklearn_pipeline_init_config[\"transformers\"][0] = {\n",
    "    \"class_name\": \"sklearn.feature_selection.SelectKBest\",\n",
    "    \"kwargs\": {\n",
    "        \"k\": 2,\n",
    "        \"score_func\": \"sklearn.feature_selection.f_regression\",\n",
    "    },\n",
    "    \"name\": \"standard_scaler\",\n",
    "    \"wrapper\": \"select_columns\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:modeling.models.sklearn_pipeline.model:`features_out` attribute is not specified. Setting `features_out` based on factual data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.086901</td>\n",
       "      <td>4.084471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.499301</td>\n",
       "      <td>-2.403360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.287332</td>\n",
       "      <td>-2.344218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.640602</td>\n",
       "      <td>-4.891933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.205942</td>\n",
       "      <td>6.570485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature_1  Feature_3\n",
       "0  -9.086901   4.084471\n",
       "1   0.499301  -2.403360\n",
       "2  -9.287332  -2.344218\n",
       "3   8.640602  -4.891933\n",
       "4   0.205942   6.570485"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_pipeline = sklearn_pipeline_factory.create()\n",
    "transformed_data = sklearn_pipeline.fit(master_data).transform(master_data)\n",
    "transformed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Setting \"wrapper\": None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Provided transformers can be used \"as-is\". Note, that default transformers from `sklearn` will return raw `numpy.ndarray` after transformation and in that case most feature validation steps will not happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sklearn_pipeline_init_config[\"transformers\"][0] = {\n",
    "    \"class_name\": \"sklearn.preprocessing.StandardScaler\",\n",
    "    \"kwargs\": {},\n",
    "    \"name\": \"standard_scaler\",\n",
    "    \"wrapper\": None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:modeling.models.sklearn_pipeline.model:`features_out` attribute is not specified. Setting `features_out` based on factual data.\n",
      "WARNING:modeling.models.sklearn_pipeline.model:Transformed data does not keep columns.\n",
      "Validation of columns after transform was not conducted. Learn how to keep columns after transformations with `optimus_core.transformer`.\n",
      "WARNING:modeling.models.sklearn_pipeline.model:Transformed data does not keep columns.\n",
      "Validation of columns after transform was not conducted. Learn how to keep columns after transformations with `optimus_core.transformer`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.52544329, -1.25879198,  0.64256259],\n",
       "       [ 0.08761726,  0.38945596, -0.49762947],\n",
       "       [-1.5591695 , -0.20265924, -0.48723576],\n",
       "       ...,\n",
       "       [ 0.22316213, -1.25470544,  1.30545579],\n",
       "       [ 0.38300939, -0.27106961,  0.31848356],\n",
       "       [ 0.19729837, -0.97483174, -1.43344984]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_pipeline = sklearn_pipeline_factory.create()\n",
    "transformed_data = sklearn_pipeline.fit(master_data).transform(master_data)\n",
    "transformed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using a `target_transformer` to leverage automatic target transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In regression problems where target has non-linear relation with feature(s), it might be useful to apply a target transformer to convert this relation into a linear one.\n",
    "Sklearn's native machinery for this task is [TransformedTargetRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.compose.TransformedTargetRegressor.html), and both `SklearnModelFactory` and `SklearnPipelineFactory` of OAI can initialize that.\n",
    "\n",
    "Examples above outline that `SklearnModelFactory` requires a so-called `model_init_config` to create a model, while `SklearnPipelineFactory` requires a `pipeline_init_config`. `target_transformer` can be injested in those configs in the same way.\n",
    "\n",
    "For `SklearnModelFactory`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_model_init_config = {\n",
    "    \"estimator\": {\n",
    "        # Estimator config\n",
    "    },\n",
    "    \"target_transformer\": {\n",
    "        \"func\": \"numpy.log1p\",\n",
    "        \"inverse_func\": \"numpy.expm1\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for `SklearnPipelineFactory`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_pipeline_init_config = {\n",
    "    \"estimator\": {\n",
    "        # Estimator config\n",
    "    },\n",
    "    \"transformers\": [\n",
    "        # Various transformers\n",
    "    ],\n",
    "    \"target_transformer\": {\n",
    "        \"transformer\": {\n",
    "            \"class_name\": \"sklearn.preprocessing.MinMaxScaler\",\n",
    "            \"kwargs\": {},\n",
    "        },\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those 2 examples above also illustrate that a `target_transformer` can be initialized in 2 mutually exclusive ways: via a pair of `func` and `inverse_func` or via a `transformer` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `KerasModel` using the `KerasModelFactory`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to build a `KerasModel` from the parameters, you'll need to define the way how your `keras` model should be built based on the parameters you specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this toy example we'll create a simple sequential `keras` model. Model structure will be predefined by users, however we'll let us manipulate with some hyperparameters.\n",
    "\n",
    "We'll start with defining custom factory inheriting `KerasModelFactory` ([API](../../../../../../docs/build/apidoc/modeling/modeling.models.keras_model.html#modeling.models.keras_model.factory.KerasModelFactory))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling.models.keras_model import KerasModelFactory\n",
    "\n",
    "\n",
    "class UserDefinedKerasModelFactory(KerasModelFactory):\n",
    "    @staticmethod\n",
    "    def create_model_instance(\n",
    "        units: int = 32,\n",
    "        learning_rate: float = 1e-03,\n",
    "    ) -> keras.Model:\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.layers.Normalization(axis=-1),\n",
    "                keras.layers.Dense(units=units, activation=\"tanh\"),\n",
    "                keras.layers.Dense(units=1),\n",
    "            ]\n",
    "        )\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            loss=\"mean_squared_error\",\n",
    "            metrics=[\n",
    "                keras.metrics.MeanAbsoluteError(),\n",
    "                keras.metrics.MeanSquaredError(),\n",
    "                keras.metrics.MeanAbsolutePercentageError(),\n",
    "            ],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's create a dictionary with parameters and initialize freshly created `UserDefinedKerasModelFactory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_init_config = {\n",
    "    \"units\": 128,\n",
    "    \"learning_rate\": 1e-05,\n",
    "}\n",
    "keras_model_factory = UserDefinedKerasModelFactory(\n",
    "    keras_model_init_config,\n",
    "    model_features,\n",
    "    model_target\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.create()` will create the instance of KerasModel with the structure defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_1 (Normalizat  (None, 3)                7         \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               512       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 648\n",
      "Trainable params: 641\n",
      "Non-trainable params: 7\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "oai_keras_model = keras_model_factory.create()\n",
    "oai_keras_model.keras_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune model using the `ModelTunerBase`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we'll show how to tune model hyperparameters using the `ModelTunerBase`[(API)](../../../../../../docs/build/apidoc/modeling/modeling.models.model_base.html#modeling.models.model_base.model_base.ModelTunerBase) class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Note</b>\n",
    "\n",
    "In order to tune model hyperparameters you'll need to pass `ModelFactoryBase`, which builds model from the hyperparameters' specification.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start from the tuner initialization: it requires tuner configuration dictionary and `ModelFactory` instance, which is used to build a model with optimal set of hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that each of the `ModelTunerBase` inheritors require instance of the Factory of its own type. Below is the table mapping tuners to `Factories`, which they require.\n",
    "\n",
    "|`ModelTunerBase`|action|`ModelFactoryBase`|\n",
    "|---|---|---|\n",
    "|`SklearnModelTuner`|requires|`SklearnModelFactory`|\n",
    "|`SklearnPipelineTuner`|requires|`SklearnPipelineFactory`|\n",
    "|`KerasModelTuner`|requires|`KerasModelFactory`|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ModelTunerBase` UML class diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ModelTunerBase.drawio-3.svg](./_images/_ModelTunerBase.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune `SklearnModel` using the `SklearnModelTuner`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start from the `SklearnModelTuner` ([API](../../../../../../docs/build/apidoc/modeling/modeling.models.sklearn_model.html#modeling.models.sklearn_model.tuner.SklearnModelTuner)) initialization. We've already initialized `SklaernModelFactory` in the section above, but we'll create it here as well for the educational purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling import SklearnModelFactory\n",
    "\n",
    "\n",
    "sklearn_model_init_config = {\n",
    "    # Object specification for sklearn compatible estimator\n",
    "    # matching the `ObjectInitConfig` structure.\n",
    "    \"estimator\": {\n",
    "        \"class_name\": \"sklearn.linear_model.SGDRegressor\",\n",
    "        \"kwargs\": {\n",
    "            \"random_state\": 123,\n",
    "            \"penalty\": \"elasticnet\",\n",
    "      }\n",
    "    },\n",
    "    # Target transform config matching the `TargetTransformerInitConfig` structure.\n",
    "    # Either transformer key should be filled,\n",
    "    # or `func` and `inverse_func` keys should be filled.\n",
    "    \"target_transformer\": {\n",
    "      # Object specification for transformer\n",
    "      # matching the `ObjectInitConfig` structure\n",
    "        \"transformer\": None,\n",
    "      # Path for the function to use as target transform\n",
    "        \"func\": \"numpy.log1p\",\n",
    "      # Path for the function to use as an inverse target transform\n",
    "        \"inverse_func\": \"numpy.expm1\",\n",
    "    }\n",
    "}\n",
    "\n",
    "sklearn_Factory = SklearnModelFactory(sklearn_model_init_config, model_features, model_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that Factory type is highlighted in the class definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function __init__ in module modeling.models.sklearn_model.tuner:\n",
      "\n",
      "__init__(self, model_factory: modeling.models.sklearn_model.factory.SklearnModelFactory, model_tuner_config: Dict[str, Any]) -> None\n",
      "    model_tuner_config structure should match `SklearnTunerConfig` structure::\n",
      "    \n",
      "        # Object specification for sklearn compatible CV tuner\n",
      "        # matching the `ObjectInitConfig` structure.\n",
      "        init:\n",
      "            class_name: sklearn.model_selection.GridSearchCV\n",
      "            kwargs:\n",
      "              n_jobs: -1\n",
      "              refit: mae\n",
      "              param_grid:\n",
      "                estimator__alpha: [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
      "                estimator__l1_ratio: [0.00001, 0.0001, 0.001, 0.01, 0.1, 1]\n",
      "              scoring:\n",
      "                mae: neg_mean_absolute_error\n",
      "                rmse: neg_root_mean_squared_error\n",
      "                r2: r2\n",
      "    \n",
      "    Args:\n",
      "        model_factory: Builder instance that produces model with corresponding type\n",
      "        model_tuner_config: Dictionary with the structure defined above\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from modeling import SklearnModelTuner\n",
    "\n",
    "\n",
    "help(SklearnModelTuner.__init__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a dictionary with the required structure and pass it into tuner initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_model_tuner_config = {\n",
    "# Object specification for sklearn compatible CV tuner\n",
    "# matching the `ObjectInitConfig` structure.\n",
    "    \"class_name\": \"sklearn.model_selection.GridSearchCV\",\n",
    "    \"kwargs\": {\n",
    "        \"n_jobs\": 1,\n",
    "        \"refit\": \"r2\",\n",
    "        \"param_grid\": {\n",
    "            \"regressor__penalty\": [\"elasticnet\",],\n",
    "        },\n",
    "        \"scoring\": {\n",
    "            \"mae\": \"neg_mean_absolute_error\",\n",
    "            \"rmse\": \"neg_root_mean_squared_error\",\n",
    "            \"r2\": \"r2\",\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "sklearn_tuner = SklearnModelTuner(sklearn_Factory, sklearn_model_tuner_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's tune model hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:modeling.models.sklearn_model.tuner:Initializing sklearn hyperparameters tuner...\n",
      "INFO:modeling.models.sklearn_model.tuner:Tuning hyperparameters...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SklearnModel(estimator=TransformedTargetRegressor(func=<ufunc 'log1p'>, inverse_func=<ufunc 'expm1'>,\n",
       "                           regressor=SGDRegressor(penalty='elasticnet',\n",
       "                                                  random_state=123)), target=\"Target\" ,features_in=['Feature_1', 'Feature_2', 'Feature_3'])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_model = sklearn_tuner.tune(data=master_data,)\n",
    "tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune `KerasModel` using the `KerasModelTuner`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to tune hyperparameters for `KerasModel` you have to define the hyperparameters tuning strategy in `make_trial_hyperparameters()` method. Note, that the resulting hyperparameters should be aligned with hyperparameters expected by Factory's method `.make_model_instance()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start from the `KerasModelTuner` ([API](../../../../../../docs/build/apidoc/modeling/modeling.models.keras_model.html#modeling.models.keras_model.tuner.KerasModel)) initialization. We've already initialized `KerasModelFactory` in the section above, but we'll create it here as well for the educational purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserDefinedKerasModelFactory(KerasModelFactory):\n",
    "    @staticmethod\n",
    "    def create_model_instance(\n",
    "        units: int = 32,\n",
    "        learning_rate: float = 1e-03,\n",
    "    ) -> keras.Model:\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.layers.Normalization(axis=-1),\n",
    "                keras.layers.Dense(units=units, activation=\"tanh\"),\n",
    "                keras.layers.Dense(units=1),\n",
    "            ]\n",
    "        )\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            loss=\"mean_squared_error\",\n",
    "            metrics=[\n",
    "                keras.metrics.MeanAbsoluteError(),\n",
    "                keras.metrics.MeanSquaredError(),\n",
    "                keras.metrics.MeanAbsolutePercentageError(),\n",
    "            ],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_init_config = {\n",
    "    \"units\": 128,\n",
    "    \"learning_rate\": 1e-05,\n",
    "}\n",
    "keras_model_factory = UserDefinedKerasModelFactory(\n",
    "    keras_model_init_config,\n",
    "    model_features,\n",
    "    model_target\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll create a tuner for the `UserDefinedKerasModelFactory`. There we'll describe the hyperparameters tuning strategy in `.make_trial_hyperparameters()` method.\n",
    "\n",
    "Note, that class inherits from the `KerasModelTuner`, which defines the interface for the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function _create_trial_hyperparameters in module modeling.models.keras_model.tuner:\n",
      "\n",
      "_create_trial_hyperparameters(hp: keras_tuner.engine.hyperparameters.HyperParameters, model_init_config: Dict[str, Any], model_hyperparameters_config: Dict[str, Any]) -> Dict[str, Any]\n",
      "    Abstract method to specify hyperparameters tuning strategy\n",
      "    for `tensorflow.keras.Model` instance using ``keras_tuner.HyperParameters``.\n",
      "    \n",
      "    This method should be overwritten by the inheritor of ``KerasModelTuner``\n",
      "    with the custom hyperparameters tuning logic. See example implementation below.\n",
      "    \n",
      "    Example implementation::\n",
      "    \n",
      "        class UserKerasModelTuner(KerasModelTuner):\n",
      "            @staticmethod\n",
      "            def _create_trial_hyperparameters(\n",
      "                #  Hyperparameter tuning API is based on `keras_tuner` package.\n",
      "                hp: keras_tuner.HyperParameters,\n",
      "                #  You also might want to use hyperparameters settings from Factory,\n",
      "                #  those are available in `model_init_config` dictionary.\n",
      "                model_init_config: tp.Dict[str, tp.Any],\n",
      "                #  Use `model_hyperparameters_config` to specify strategy.\n",
      "                #  See the example below.\n",
      "                model_hyperparameters_config: tp.Dict[str, tp.Any],\n",
      "            ) -> tp.Dict[str, tp.Any]:\n",
      "                units = hp.Int(\n",
      "                    \"units\",\n",
      "                    min_value=model_hyperparameters_config[\"units\"][\"min_value\"],\n",
      "                    max_value=model_hyperparameters_config[\"units\"][\"max_value\"],\n",
      "                    sampling=model_hyperparameters_config[\"units\"][\"sampling\"],\n",
      "                )\n",
      "                learning_rate = model_init_config[\"learning_rate\"]\n",
      "                return {\"units\": units, \"learning_rate\": learning_rate}\n",
      "    \n",
      "    Args:\n",
      "        hp: instance to tune the ``keras_tuner.HyperParameters``\n",
      "        model_init_config: model initialization config\n",
      "         used for ``KerasModelFactory``\n",
      "        model_hyperparameters_config: dictionary with\n",
      "         hyperparameters tuning specification\n",
      "    \n",
      "    Returns:\n",
      "        Dictionary mapping hyperparameter name to trial hyperparameter value\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from modeling.models.keras_model import KerasModelTuner\n",
    "\n",
    "\n",
    "help(KerasModelTuner._create_trial_hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning API is based on `keras_tuner` package. Learn more about the `keras_tuner` on their [website](https://keras.io/guides/keras_tuner/getting_started/#tune-the-model-architecture).\n",
    "\n",
    "In this freshly created tuner we'll reuse the original value for the `units` from Factory, `units` won't be tuned. But for the `learning_rate` we'll specify space for tuning and sampling strategy in `model_hyperparameters_config` dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner\n",
    "\n",
    "\n",
    "class UserDefinedKerasModelTuner(KerasModelTuner):\n",
    "    @staticmethod\n",
    "    def _create_trial_hyperparameters(\n",
    "        #  Hyperparameter tuning API is based on `keras_tuner` package. \n",
    "        hp: keras_tuner.HyperParameters,\n",
    "        #  You also might want to use hyperparameters settings from Factory,\n",
    "        #  those are available in `model_init_config` dictionary.\n",
    "        model_init_config: tp.Dict[str, tp.Any],\n",
    "        #  Use `model_hyperparameters_config` to specify strategy.\n",
    "        #  See the example below.\n",
    "        model_hyperparameters_config: tp.Dict[str, tp.Any],\n",
    "    ) -> tp.Dict[str, tp.Any]:\n",
    "        units = hp.Int(\n",
    "            \"units\",\n",
    "            min_value=model_hyperparameters_config[\"units\"][\"min_value\"],\n",
    "            max_value=model_hyperparameters_config[\"units\"][\"max_value\"],\n",
    "            sampling=model_hyperparameters_config[\"units\"][\"sampling\"],\n",
    "        )\n",
    "        learning_rate = model_init_config[\"learning_rate\"]\n",
    "        return {\"units\": units, \"learning_rate\": learning_rate}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's create a dictionary with the required structure and pass it into tuner initialization. See the full list of tuner settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function __init__ in module modeling.models.keras_model.tuner:\n",
      "\n",
      "__init__(self, model_factory: modeling.models.keras_model.factory.KerasModelFactory, model_tuner_config: Dict[str, Any]) -> None\n",
      "    Structure of ``model_tuner_config`` should be\n",
      "    aligned with ``KerasModelTunerConfig``::\n",
      "    \n",
      "        # Path to instance of tuner in keras_tuner\n",
      "        tuner: keras_tuner.RandomSearch\n",
      "        # Metric for hyperparameters objective and direction\n",
      "        objective_metric: mean_squared_error\n",
      "        objective_direction: min\n",
      "        # Number of hyperparameter tuning trials and executions per trial\n",
      "        max_trials: 5\n",
      "        executions_per_trial: 1\n",
      "        # Project name\n",
      "        project_name: oai-keras-model\n",
      "        # Path to the directory to keep training artefacts\n",
      "        tuning_artefacts_dir: data/sample_keras_model_hp\n",
      "    \n",
      "    Args:\n",
      "        model_factory: instance of the KerasModelFactory\n",
      "        model_tuner_config: configuration dictionary\n",
      "         with the structure defined above\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(UserDefinedKerasModelTuner.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_tuner_config = {\n",
    "    \"max_trials\": 5,\n",
    "    \"tuner\": \"keras_tuner.RandomSearch\",\n",
    "    \"objective_metric\": \"mean_squared_error\",\n",
    "    \"objective_direction\": \"min\",\n",
    "}\n",
    "\n",
    "model_hyperparameters_config = {\n",
    "    \"units\": {\n",
    "        \"min_value\": 8,\n",
    "        \"max_value\": 1024,\n",
    "        \"sampling\": \"log\"\n",
    "    }\n",
    "}\n",
    "\n",
    "keras_tuner = UserDefinedKerasModelTuner(keras_model_factory, keras_model_tuner_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's finally tune the hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 28s]\n",
      "mean_squared_error: 3084.65869140625\n",
      "\n",
      "Best mean_squared_error So Far: 2999.153076171875\n",
      "Total elapsed time: 00h 03m 22s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuned_model = keras_tuner.tune(\n",
    "    master_data, \n",
    "    model_hyperparameters_config, \n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizatio  (None, 3)                7         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 384)               1536      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 385       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,928\n",
      "Trainable params: 1,921\n",
      "Non-trainable params: 7\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tuned_model.keras_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`functional` subpackage allows you to work with classes listed above in the functional workaround. This might be especially useful when working with pipelines or other orchestration tools that require simple callable objects (e.g., Kedro).\n",
    "\n",
    "Most of the functions are designed in a way that simply expects the class instance as an input, calls a single method of the class instance, and returns the output. Sometimes outputs get transformed into the objects that work better for storing on dist, e.g., we transform the dictionary with feature importances, which is an output of `ModelBase.get_feature_importance()` into the `pd.DataFrame`.\n",
    "\n",
    "You can find demo of how these functions work in [modeling tutorial](./modeling.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subpackage diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![diagram](./_images/_models_functional.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Click here](./_images/_models_functional.png) to expand diagram above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oai_dev_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "643px",
    "left": "66px",
    "top": "110px",
    "width": "377.989136px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
