{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae89c4d2-9a7b-4352-b0d5-6698221787a1",
   "metadata": {},
   "source": [
    "# Baselining tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1357fe-9464-4871-b12f-f471d2158825",
   "metadata": {},
   "source": [
    "The aim of this tutorial is to create a baseline model. It can be later used for impact estimation when an intervention that changes the use case target value is done.\n",
    "\n",
    "The idea behind baseline modeling is to find what whould have been the plant output if no interventions had been done. If we had two identical plants available with identical input product properties and identical operating modes, we could test the interventions in one plane and use the other one as control (baseline). However, this is extremely rare, so baseline is usually found through a model.\n",
    "\n",
    "The model finds what would have been the target value if no interventions had been made. To do so, relevant data is selected and the model is built. Finally, the results are validated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2f77cf-7679-42f3-a480-d61f3f4b17e1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "604264a2-f022-4645-9634-3b3e34e3bc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1519b6d-d572-43b9-9420-b46151c7d69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolve path when used in a usecase project\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, str(Path(\"../../\").resolve()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d4270d-c14b-4bec-95c2-795711f0a2f8",
   "metadata": {},
   "source": [
    "First, we get our datasets. We have two datas sources available, which reperesent plant behaviour before interventions and the expected value after them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f87b8e6-7ddc-401f-bd3a-0968df142d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "from modeling import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab5156b-cd74-4a2f-85d7-4612f3fd70bd",
   "metadata": {},
   "source": [
    "First we have the data before interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b67dec4-acbf-422f-a3ec-b39ca00b88f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_flow01</th>\n",
       "      <th>air_flow02</th>\n",
       "      <th>air_flow03</th>\n",
       "      <th>air_flow04</th>\n",
       "      <th>air_flow05</th>\n",
       "      <th>air_flow06</th>\n",
       "      <th>air_flow07</th>\n",
       "      <th>amina_flow</th>\n",
       "      <th>column_level01</th>\n",
       "      <th>column_level02</th>\n",
       "      <th>...</th>\n",
       "      <th>ore_pulp_flow</th>\n",
       "      <th>ore_pulp_ph</th>\n",
       "      <th>silica_conc</th>\n",
       "      <th>silica_feed</th>\n",
       "      <th>starch_flow</th>\n",
       "      <th>iron_minus_silica</th>\n",
       "      <th>feed_diff_divide_silica</th>\n",
       "      <th>total_column_level</th>\n",
       "      <th>total_air_flow</th>\n",
       "      <th>silica_conc_lagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1287.00</td>\n",
       "      <td>1287.00</td>\n",
       "      <td>1287.00</td>\n",
       "      <td>1287.00</td>\n",
       "      <td>1287.00</td>\n",
       "      <td>1287.00</td>\n",
       "      <td>1287.00</td>\n",
       "      <td>1287.00</td>\n",
       "      <td>1287.00</td>\n",
       "      <td>1287.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1287.00</td>\n",
       "      <td>1287.00</td>\n",
       "      <td>1287.00</td>\n",
       "      <td>1287.00</td>\n",
       "      <td>1287.00</td>\n",
       "      <td>1287.00</td>\n",
       "      <td>1287.00</td>\n",
       "      <td>1287.00</td>\n",
       "      <td>1287.00</td>\n",
       "      <td>1285.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>279.50</td>\n",
       "      <td>276.14</td>\n",
       "      <td>280.25</td>\n",
       "      <td>299.05</td>\n",
       "      <td>299.13</td>\n",
       "      <td>286.31</td>\n",
       "      <td>286.56</td>\n",
       "      <td>487.28</td>\n",
       "      <td>521.74</td>\n",
       "      <td>522.09</td>\n",
       "      <td>...</td>\n",
       "      <td>397.75</td>\n",
       "      <td>9.80</td>\n",
       "      <td>12.79</td>\n",
       "      <td>14.48</td>\n",
       "      <td>2953.80</td>\n",
       "      <td>41.98</td>\n",
       "      <td>4.20</td>\n",
       "      <td>3280.99</td>\n",
       "      <td>2006.93</td>\n",
       "      <td>2.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28.20</td>\n",
       "      <td>28.56</td>\n",
       "      <td>27.94</td>\n",
       "      <td>1.77</td>\n",
       "      <td>2.03</td>\n",
       "      <td>22.50</td>\n",
       "      <td>22.14</td>\n",
       "      <td>73.39</td>\n",
       "      <td>114.52</td>\n",
       "      <td>111.60</td>\n",
       "      <td>...</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.34</td>\n",
       "      <td>3.23</td>\n",
       "      <td>6.65</td>\n",
       "      <td>727.90</td>\n",
       "      <td>11.68</td>\n",
       "      <td>3.24</td>\n",
       "      <td>496.81</td>\n",
       "      <td>119.75</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>200.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>293.72</td>\n",
       "      <td>287.21</td>\n",
       "      <td>200.00</td>\n",
       "      <td>200.14</td>\n",
       "      <td>300.00</td>\n",
       "      <td>303.84</td>\n",
       "      <td>228.22</td>\n",
       "      <td>...</td>\n",
       "      <td>378.32</td>\n",
       "      <td>9.00</td>\n",
       "      <td>8.15</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2489.12</td>\n",
       "      <td>1605.37</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>250.07</td>\n",
       "      <td>250.08</td>\n",
       "      <td>250.07</td>\n",
       "      <td>299.84</td>\n",
       "      <td>299.78</td>\n",
       "      <td>250.83</td>\n",
       "      <td>250.63</td>\n",
       "      <td>437.51</td>\n",
       "      <td>449.33</td>\n",
       "      <td>449.55</td>\n",
       "      <td>...</td>\n",
       "      <td>399.43</td>\n",
       "      <td>9.57</td>\n",
       "      <td>10.26</td>\n",
       "      <td>8.98</td>\n",
       "      <td>2256.70</td>\n",
       "      <td>33.10</td>\n",
       "      <td>1.69</td>\n",
       "      <td>2803.74</td>\n",
       "      <td>1948.68</td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>299.85</td>\n",
       "      <td>299.43</td>\n",
       "      <td>299.90</td>\n",
       "      <td>299.92</td>\n",
       "      <td>299.89</td>\n",
       "      <td>299.81</td>\n",
       "      <td>299.81</td>\n",
       "      <td>497.25</td>\n",
       "      <td>499.96</td>\n",
       "      <td>499.97</td>\n",
       "      <td>...</td>\n",
       "      <td>399.93</td>\n",
       "      <td>9.82</td>\n",
       "      <td>12.24</td>\n",
       "      <td>13.68</td>\n",
       "      <td>2935.82</td>\n",
       "      <td>42.21</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3204.41</td>\n",
       "      <td>2092.12</td>\n",
       "      <td>2.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>299.92</td>\n",
       "      <td>299.85</td>\n",
       "      <td>299.93</td>\n",
       "      <td>299.95</td>\n",
       "      <td>299.97</td>\n",
       "      <td>299.93</td>\n",
       "      <td>299.93</td>\n",
       "      <td>543.48</td>\n",
       "      <td>599.88</td>\n",
       "      <td>599.33</td>\n",
       "      <td>...</td>\n",
       "      <td>400.33</td>\n",
       "      <td>10.03</td>\n",
       "      <td>14.49</td>\n",
       "      <td>19.56</td>\n",
       "      <td>3462.87</td>\n",
       "      <td>50.88</td>\n",
       "      <td>5.62</td>\n",
       "      <td>3608.11</td>\n",
       "      <td>2099.09</td>\n",
       "      <td>2.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>300.00</td>\n",
       "      <td>300.00</td>\n",
       "      <td>300.00</td>\n",
       "      <td>300.00</td>\n",
       "      <td>300.00</td>\n",
       "      <td>300.00</td>\n",
       "      <td>300.00</td>\n",
       "      <td>698.68</td>\n",
       "      <td>800.00</td>\n",
       "      <td>800.00</td>\n",
       "      <td>...</td>\n",
       "      <td>410.00</td>\n",
       "      <td>10.77</td>\n",
       "      <td>27.77</td>\n",
       "      <td>30.00</td>\n",
       "      <td>5943.95</td>\n",
       "      <td>63.00</td>\n",
       "      <td>31.50</td>\n",
       "      <td>5094.78</td>\n",
       "      <td>2099.91</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       air_flow01  air_flow02  air_flow03  air_flow04  air_flow05  air_flow06  \\\n",
       "count     1287.00     1287.00     1287.00     1287.00     1287.00     1287.00   \n",
       "mean       279.50      276.14      280.25      299.05      299.13      286.31   \n",
       "std         28.20       28.56       27.94        1.77        2.03       22.50   \n",
       "min        200.00      200.00      200.00      293.72      287.21      200.00   \n",
       "25%        250.07      250.08      250.07      299.84      299.78      250.83   \n",
       "50%        299.85      299.43      299.90      299.92      299.89      299.81   \n",
       "75%        299.92      299.85      299.93      299.95      299.97      299.93   \n",
       "max        300.00      300.00      300.00      300.00      300.00      300.00   \n",
       "\n",
       "       air_flow07  amina_flow  column_level01  column_level02  ...  \\\n",
       "count     1287.00     1287.00         1287.00         1287.00  ...   \n",
       "mean       286.56      487.28          521.74          522.09  ...   \n",
       "std         22.14       73.39          114.52          111.60  ...   \n",
       "min        200.14      300.00          303.84          228.22  ...   \n",
       "25%        250.63      437.51          449.33          449.55  ...   \n",
       "50%        299.81      497.25          499.96          499.97  ...   \n",
       "75%        299.93      543.48          599.88          599.33  ...   \n",
       "max        300.00      698.68          800.00          800.00  ...   \n",
       "\n",
       "       ore_pulp_flow  ore_pulp_ph  silica_conc  silica_feed  starch_flow  \\\n",
       "count        1287.00      1287.00      1287.00      1287.00      1287.00   \n",
       "mean          397.75         9.80        12.79        14.48      2953.80   \n",
       "std             6.90         0.34         3.23         6.65       727.90   \n",
       "min           378.32         9.00         8.15         2.00      2000.00   \n",
       "25%           399.43         9.57        10.26         8.98      2256.70   \n",
       "50%           399.93         9.82        12.24        13.68      2935.82   \n",
       "75%           400.33        10.03        14.49        19.56      3462.87   \n",
       "max           410.00        10.77        27.77        30.00      5943.95   \n",
       "\n",
       "       iron_minus_silica  feed_diff_divide_silica  total_column_level  \\\n",
       "count            1287.00                  1287.00             1287.00   \n",
       "mean               41.98                     4.20             3280.99   \n",
       "std                11.68                     3.24              496.81   \n",
       "min                15.00                     0.50             2489.12   \n",
       "25%                33.10                     1.69             2803.74   \n",
       "50%                42.21                     3.08             3204.41   \n",
       "75%                50.88                     5.62             3608.11   \n",
       "max                63.00                    31.50             5094.78   \n",
       "\n",
       "       total_air_flow  silica_conc_lagged  \n",
       "count         1287.00             1285.00  \n",
       "mean          2006.93                2.30  \n",
       "std            119.75                1.00  \n",
       "min           1605.37                1.00  \n",
       "25%           1948.68                1.53  \n",
       "50%           2092.12                2.02  \n",
       "75%           2099.09                2.87  \n",
       "max           2099.91                5.00  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_before_oai = datasets.get_sample_baselining_historical_data()\n",
    "df_before_oai.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5f5b0f-dc11-4e1b-ab21-762a7519fb35",
   "metadata": {},
   "source": [
    "and the expected value after them. The expected value after interventions are:\n",
    "* Actual sensor values for the context variables.\n",
    "* Recommended controls yield by the optimizer for control variables.\n",
    "* Predicted target value yield by the optimizer for the target value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66f4f34f-b95e-41fc-8208-a0e8dd8b2deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_flow01</th>\n",
       "      <th>air_flow02</th>\n",
       "      <th>air_flow03</th>\n",
       "      <th>air_flow04</th>\n",
       "      <th>air_flow05</th>\n",
       "      <th>air_flow06</th>\n",
       "      <th>air_flow07</th>\n",
       "      <th>amina_flow</th>\n",
       "      <th>column_level01</th>\n",
       "      <th>column_level02</th>\n",
       "      <th>...</th>\n",
       "      <th>ore_pulp_flow</th>\n",
       "      <th>ore_pulp_ph</th>\n",
       "      <th>silica_conc</th>\n",
       "      <th>silica_feed</th>\n",
       "      <th>starch_flow</th>\n",
       "      <th>iron_minus_silica</th>\n",
       "      <th>feed_diff_divide_silica</th>\n",
       "      <th>total_column_level</th>\n",
       "      <th>total_air_flow</th>\n",
       "      <th>silica_conc_lagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>81.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>...</td>\n",
       "      <td>81.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>81.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>294.79</td>\n",
       "      <td>295.13</td>\n",
       "      <td>296.10</td>\n",
       "      <td>298.08</td>\n",
       "      <td>297.39</td>\n",
       "      <td>295.27</td>\n",
       "      <td>294.90</td>\n",
       "      <td>516.36</td>\n",
       "      <td>473.78</td>\n",
       "      <td>526.08</td>\n",
       "      <td>...</td>\n",
       "      <td>391.06</td>\n",
       "      <td>9.42</td>\n",
       "      <td>12.26</td>\n",
       "      <td>17.23</td>\n",
       "      <td>3064.88</td>\n",
       "      <td>36.61</td>\n",
       "      <td>2.57</td>\n",
       "      <td>3028.60</td>\n",
       "      <td>2071.66</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19.85</td>\n",
       "      <td>18.85</td>\n",
       "      <td>15.26</td>\n",
       "      <td>2.02</td>\n",
       "      <td>3.73</td>\n",
       "      <td>19.47</td>\n",
       "      <td>19.48</td>\n",
       "      <td>67.17</td>\n",
       "      <td>102.48</td>\n",
       "      <td>87.61</td>\n",
       "      <td>...</td>\n",
       "      <td>11.31</td>\n",
       "      <td>0.20</td>\n",
       "      <td>3.53</td>\n",
       "      <td>5.52</td>\n",
       "      <td>627.91</td>\n",
       "      <td>8.76</td>\n",
       "      <td>1.56</td>\n",
       "      <td>431.60</td>\n",
       "      <td>93.76</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>200.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>214.62</td>\n",
       "      <td>293.46</td>\n",
       "      <td>287.82</td>\n",
       "      <td>200.06</td>\n",
       "      <td>200.00</td>\n",
       "      <td>302.13</td>\n",
       "      <td>399.21</td>\n",
       "      <td>399.06</td>\n",
       "      <td>...</td>\n",
       "      <td>378.54</td>\n",
       "      <td>9.00</td>\n",
       "      <td>7.46</td>\n",
       "      <td>7.56</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2598.05</td>\n",
       "      <td>1609.41</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>299.82</td>\n",
       "      <td>299.71</td>\n",
       "      <td>299.89</td>\n",
       "      <td>296.54</td>\n",
       "      <td>295.02</td>\n",
       "      <td>299.94</td>\n",
       "      <td>299.71</td>\n",
       "      <td>491.44</td>\n",
       "      <td>399.82</td>\n",
       "      <td>466.39</td>\n",
       "      <td>...</td>\n",
       "      <td>381.01</td>\n",
       "      <td>9.28</td>\n",
       "      <td>9.97</td>\n",
       "      <td>13.70</td>\n",
       "      <td>2599.22</td>\n",
       "      <td>30.97</td>\n",
       "      <td>1.51</td>\n",
       "      <td>2776.49</td>\n",
       "      <td>2089.46</td>\n",
       "      <td>1.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>299.88</td>\n",
       "      <td>299.84</td>\n",
       "      <td>299.92</td>\n",
       "      <td>298.71</td>\n",
       "      <td>299.87</td>\n",
       "      <td>300.00</td>\n",
       "      <td>300.00</td>\n",
       "      <td>522.26</td>\n",
       "      <td>402.65</td>\n",
       "      <td>500.13</td>\n",
       "      <td>...</td>\n",
       "      <td>386.29</td>\n",
       "      <td>9.46</td>\n",
       "      <td>11.72</td>\n",
       "      <td>16.60</td>\n",
       "      <td>2990.63</td>\n",
       "      <td>37.67</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2922.25</td>\n",
       "      <td>2097.09</td>\n",
       "      <td>2.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>299.93</td>\n",
       "      <td>299.93</td>\n",
       "      <td>299.94</td>\n",
       "      <td>299.92</td>\n",
       "      <td>300.00</td>\n",
       "      <td>300.00</td>\n",
       "      <td>300.00</td>\n",
       "      <td>558.30</td>\n",
       "      <td>590.60</td>\n",
       "      <td>599.50</td>\n",
       "      <td>...</td>\n",
       "      <td>400.82</td>\n",
       "      <td>9.56</td>\n",
       "      <td>13.39</td>\n",
       "      <td>20.81</td>\n",
       "      <td>3455.24</td>\n",
       "      <td>41.73</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3159.40</td>\n",
       "      <td>2099.17</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>299.99</td>\n",
       "      <td>300.00</td>\n",
       "      <td>299.98</td>\n",
       "      <td>300.00</td>\n",
       "      <td>300.00</td>\n",
       "      <td>300.00</td>\n",
       "      <td>300.00</td>\n",
       "      <td>698.47</td>\n",
       "      <td>800.00</td>\n",
       "      <td>800.00</td>\n",
       "      <td>...</td>\n",
       "      <td>410.00</td>\n",
       "      <td>9.79</td>\n",
       "      <td>26.93</td>\n",
       "      <td>30.00</td>\n",
       "      <td>4563.06</td>\n",
       "      <td>52.27</td>\n",
       "      <td>6.91</td>\n",
       "      <td>4795.49</td>\n",
       "      <td>2099.71</td>\n",
       "      <td>4.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       air_flow01  air_flow02  air_flow03  air_flow04  air_flow05  air_flow06  \\\n",
       "count       81.00       81.00       81.00       81.00       81.00       81.00   \n",
       "mean       294.79      295.13      296.10      298.08      297.39      295.27   \n",
       "std         19.85       18.85       15.26        2.02        3.73       19.47   \n",
       "min        200.00      200.00      214.62      293.46      287.82      200.06   \n",
       "25%        299.82      299.71      299.89      296.54      295.02      299.94   \n",
       "50%        299.88      299.84      299.92      298.71      299.87      300.00   \n",
       "75%        299.93      299.93      299.94      299.92      300.00      300.00   \n",
       "max        299.99      300.00      299.98      300.00      300.00      300.00   \n",
       "\n",
       "       air_flow07  amina_flow  column_level01  column_level02  ...  \\\n",
       "count       81.00       81.00           81.00           81.00  ...   \n",
       "mean       294.90      516.36          473.78          526.08  ...   \n",
       "std         19.48       67.17          102.48           87.61  ...   \n",
       "min        200.00      302.13          399.21          399.06  ...   \n",
       "25%        299.71      491.44          399.82          466.39  ...   \n",
       "50%        300.00      522.26          402.65          500.13  ...   \n",
       "75%        300.00      558.30          590.60          599.50  ...   \n",
       "max        300.00      698.47          800.00          800.00  ...   \n",
       "\n",
       "       ore_pulp_flow  ore_pulp_ph  silica_conc  silica_feed  starch_flow  \\\n",
       "count          81.00        81.00        81.00        81.00        81.00   \n",
       "mean          391.06         9.42        12.26        17.23      3064.88   \n",
       "std            11.31         0.20         3.53         5.52       627.91   \n",
       "min           378.54         9.00         7.46         7.56      2000.00   \n",
       "25%           381.01         9.28         9.97        13.70      2599.22   \n",
       "50%           386.29         9.46        11.72        16.60      2990.63   \n",
       "75%           400.82         9.56        13.39        20.81      3455.24   \n",
       "max           410.00         9.79        26.93        30.00      4563.06   \n",
       "\n",
       "       iron_minus_silica  feed_diff_divide_silica  total_column_level  \\\n",
       "count              81.00                    81.00               81.00   \n",
       "mean               36.61                     2.57             3028.60   \n",
       "std                 8.76                     1.56              431.60   \n",
       "min                15.00                     0.50             2598.05   \n",
       "25%                30.97                     1.51             2776.49   \n",
       "50%                37.67                     2.25             2922.25   \n",
       "75%                41.73                     3.10             3159.40   \n",
       "max                52.27                     6.91             4795.49   \n",
       "\n",
       "       total_air_flow  silica_conc_lagged  \n",
       "count           81.00               81.00  \n",
       "mean          2071.66                2.68  \n",
       "std             93.76                1.01  \n",
       "min           1609.41                1.10  \n",
       "25%           2089.46                1.86  \n",
       "50%           2097.09                2.49  \n",
       "75%           2099.17                3.41  \n",
       "max           2099.71                4.95  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_after_oai = datasets.get_sample_baselining_recs_data()\n",
    "df_after_oai.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebd8041-0121-4f86-be45-e1e07ec78b37",
   "metadata": {},
   "source": [
    "## Data filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e62e4ba-ec45-49d4-8dc3-336bdffbb9f0",
   "metadata": {},
   "source": [
    "The data used to train the baseline should be historical data where no interventions have been made. To select the correct data, we perform two stepts:\n",
    "1. Feature selection\n",
    "2. Time period selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837274e3-ce48-483b-b2c9-ae8799033ca5",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1756d600-1614-4e7d-8148-c45986b40da6",
   "metadata": {},
   "source": [
    "Baseline model features should only contain input tags that will not change because of the interventions. If an optimization step is performed, the following tags have to be avoided:\n",
    "- Tags that are used for optimization should be excluded. Otherwise, a change cause by the interventions would change the baseline value and it would not be useful for impact calculation.\n",
    "- Output tags could be equally modified by the interventions. Hence, they should be excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1112209e-78a8-4d45-8fbe-a76c1f79125c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iron_feed', 'silica_feed', 'feed_diff_divide_silica']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_features = ['iron_feed', 'silica_feed', 'feed_diff_divide_silica']\n",
    "model_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed80cd3-5591-4947-bfe2-f1773142efc1",
   "metadata": {},
   "source": [
    "We also define the target value and the datetime column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86f50399-4f3e-4fe3-b4b0-75da1f62630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = \"silica_conc\"\n",
    "datetime_column = \"timestamp\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461d5c54-5608-482c-a0fe-9d955432561b",
   "metadata": {},
   "source": [
    "### Time period selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7cc10a-91be-4bda-91a3-335b39b3b1f5",
   "metadata": {},
   "source": [
    "Time periods should...\n",
    "- not overlap with any other initiative to have a clean impact narrative\n",
    "- represent the maximum number of possible plant conditions, such as\n",
    "    - operating modes\n",
    "    - type and quality of input materials\n",
    "    - seasonality\n",
    "    - equipment shutdowns\n",
    "    - ...\n",
    " \n",
    "In this example we will assume that the data we have available meets this criteria. In a real scenario, this should be checked with client and SMEs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6617d28f-283b-4c36-a2d3-1874ce5caf3b",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bf4590-82ec-4f41-940c-dac791a3af05",
   "metadata": {},
   "source": [
    "We will build the baseline model using the functionalities of the `modeling` package. We assume familiarity with them for this tutorial. Please check the [modeling tutorial](./modeling.ipynb) to learn how to use them in more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c38ae6d-2ed8-4576-8930-8fafb655bce9",
   "metadata": {},
   "source": [
    "First, we split the data in train and test sets. To learn more about the splitting options, check the [splitter tutorial](./splitter_base.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "146d7191-087e-4151-8e65-a1ccb30a1d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:modeling.splitters._splitters.base_splitter:Length of data before splitting is 1287\n",
      "INFO:modeling.splitters._splitters.by_last_window:Splitting by datetime: 2017-08-16 20:00:00\n",
      "INFO:modeling.splitters._splitters.base_splitter:Length of the train data after splitting is 1175, length of the test data after splitting is 112.\n"
     ]
    }
   ],
   "source": [
    "from modeling import create_splitter, split_data\n",
    "splitter = create_splitter(\n",
    "    \"last_window\", \n",
    "    splitting_parameters={\n",
    "        \"datetime_column\": datetime_column,\n",
    "        \"freq\": \"14D\",\n",
    "    },\n",
    ")\n",
    "train_data, test_data = split_data(df_before_oai, splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965fb666-a8da-4cb7-bebf-e8dcc8d61e4b",
   "metadata": {},
   "source": [
    "After this step, we need to choose which model class we will be using for training. Here, we will explore the main two approaches:\n",
    "- Linear models\n",
    "- KNN\n",
    "\n",
    "**We recommend to use linear models whenever possible**. The linear model is not as popular due to lack of usage and explanation guide. For more details of comparison see the brix post \"OAI impact calculation guidelines\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c206d472-b815-47ee-95e5-552d351bdd17",
   "metadata": {},
   "source": [
    "### Linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9869738d-28b3-46df-b29c-27c4100a7914",
   "metadata": {},
   "source": [
    "#### Pipeline inicialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c1aaf2-b11f-4887-bf1a-66c5ed7d0c0d",
   "metadata": {},
   "source": [
    "First we initialize our model. To do so, we use the same set up as in training any other models. For details on how to set up a model training pipeline see the [modeling tutorial notebook](./modeling.ipynb).\n",
    "\n",
    "Below we set up a linear model. Instead of using a simple linear regression, we will use a `ElasticNet` model to be more flexible in choosing hyperparameters. We also add a `StandardScaler` to standardize the data before it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1306671b-e2c5-4581-ad2f-af523a05026a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SklearnPipeline(estimator=Pipeline(steps=[('standard_scaler',\n",
       "                 SklearnTransform(transformer=StandardScaler())),\n",
       "                ('estimator', ElasticNet(random_state=123))]), target=\"silica_conc\" ,features_in=['iron_feed', 'silica_feed', 'feed_diff_divide_silica'], features_out=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modeling import create_model_factory\n",
    "\n",
    "\n",
    "linear_pipeline_init_config = {\n",
    "    'estimator': {\n",
    "        'class_name': 'sklearn.linear_model.ElasticNet',\n",
    "        'kwargs': {\n",
    "            'random_state': 123,\n",
    "            'max_iter': 1000\n",
    "        }\n",
    "    },\n",
    "    'transformers': [\n",
    "        {\n",
    "            'class_name': 'sklearn.preprocessing.StandardScaler',\n",
    "            'kwargs': {},\n",
    "            'name': 'standard_scaler',\n",
    "            'wrapper': 'preserve_columns',\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "linear_pipeline_factory = create_model_factory(\n",
    "    model_factory_type=\"modeling.SklearnPipelineFactory\",\n",
    "    model_init_config=linear_pipeline_init_config,\n",
    "    features=model_features,\n",
    "    target=target_column,\n",
    ")\n",
    "\n",
    "linear_pipeline = linear_pipeline_factory.create()\n",
    "linear_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681128ae-dbd7-4a19-9bf7-4483571441bc",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d349fa8c-4f50-400c-8bf2-e1be00f8aa52",
   "metadata": {},
   "source": [
    "Next, we will tune our model hyperparameters. Again, more detail on the tuning process can be found on the [modeling tutorial notebook](./modeling.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a31f9b83-f0c1-42f0-ac13-12f451d5ed1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:modeling.models.sklearn_pipeline.model:`features_out` attribute is not specified. Setting `features_out` based on factual data.\n",
      "INFO:modeling.models.sklearn_pipeline.tuner:Initializing sklearn hyperparameters tuner...\n",
      "INFO:modeling.models.sklearn_pipeline.tuner:Tuning hyperparameters...\n",
      "The best params:\n",
      "\n",
      "alpha: 0.1\n",
      "copy_X: True\n",
      "fit_intercept: True\n",
      "l1_ratio: 0.01\n",
      "max_iter: 1000\n",
      "positive: False\n",
      "precompute: False\n",
      "random_state: 123\n",
      "selection: cyclic\n",
      "tol: 0.0001\n",
      "warm_start: False\n"
     ]
    }
   ],
   "source": [
    "from modeling import create_tuner, tune_model\n",
    "\n",
    "linear_pipeline_tuner_config = {\n",
    "    'class_name': 'sklearn.model_selection.GridSearchCV',\n",
    "    'kwargs': {\n",
    "        'n_jobs': -1,\n",
    "        'refit': 'mae',\n",
    "        'param_grid': {\n",
    "            'estimator__alpha': [0.1, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "            'estimator__l1_ratio': [0.01, 0.2, 0.4, 0.6, 0.8, 1],\n",
    "        },\n",
    "        'scoring': {\n",
    "            'mae': 'neg_mean_absolute_error',\n",
    "            'rmse': 'neg_root_mean_squared_error',\n",
    "            'r2': 'r2',\n",
    "        },\n",
    "        'cv': 5,\n",
    "    }\n",
    "}\n",
    "\n",
    "linear_pipeline_tuner = create_tuner(\n",
    "    model_factory=linear_pipeline_factory,\n",
    "    model_tuner_type=\"modeling.SklearnPipelineTuner\",\n",
    "    tuner_config=linear_pipeline_tuner_config,\n",
    ")\n",
    "\n",
    "linear_pipeline = tune_model(\n",
    "    model_tuner=linear_pipeline_tuner,\n",
    "    data=train_data,\n",
    "    hyperparameters_config=None,\n",
    ")\n",
    "\n",
    "print(\"The best params:\\n\")\n",
    "for k, v in linear_pipeline.estimator.get_params().items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d0b467-0b4e-4db8-a6f0-9e8054b33e74",
   "metadata": {},
   "source": [
    "We will use the hyperparameters shown above to train the model. We osberve that the best parameters prioritize l2 regularization in contrast with l1 regulatization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f40803-e770-4853-a672-e4e9001e6de5",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43263a96-c973-44e0-890f-d841a6b5f89d",
   "metadata": {},
   "source": [
    "Finally, we can train the model using the pipeline after hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce8fea0d-4ee1-4d63-9a4a-4231667a2789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling import train_model\n",
    "\n",
    "linear_pipeline = train_model(linear_pipeline, train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bb6298-142b-4372-86ad-c59ae3c66cfb",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d5ab4d-25fc-427e-8ff6-e807c6828604",
   "metadata": {},
   "source": [
    "We will show main metrics and feature importance. Feature importance should be checked with SMEs to ensure that it correctly represents the expected behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8137358d-351e-4997-a8b5-5dd383e0696a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_metric_value</th>\n",
       "      <th>test_metric_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>2.405719</td>\n",
       "      <td>2.413806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>3.177314</td>\n",
       "      <td>2.999873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse</th>\n",
       "      <td>10.095326</td>\n",
       "      <td>8.999240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mape</th>\n",
       "      <td>0.189729</td>\n",
       "      <td>0.196221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_squared</th>\n",
       "      <td>0.046954</td>\n",
       "      <td>-0.052942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_score</th>\n",
       "      <td>0.046954</td>\n",
       "      <td>-0.052674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             train_metric_value  test_metric_value\n",
       "metric_name                                       \n",
       "mae                    2.405719           2.413806\n",
       "rmse                   3.177314           2.999873\n",
       "mse                   10.095326           8.999240\n",
       "mape                   0.189729           0.196221\n",
       "r_squared              0.046954          -0.052942\n",
       "var_score              0.046954          -0.052674"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modeling import calculate_metrics\n",
    "import pandas as pd\n",
    "\n",
    "train_metrics = calculate_metrics(\n",
    "    train_data, model=linear_pipeline,\n",
    ")\n",
    "\n",
    "test_metrics = calculate_metrics(\n",
    "    test_data, model=linear_pipeline,\n",
    ")\n",
    "\n",
    "linear_metrics = pd.DataFrame(\n",
    "    {\n",
    "        \"train_metric_value\": train_metrics,\n",
    "        \"test_metric_value\": test_metrics,\n",
    "    },\n",
    ").rename_axis(\"metric_name\")\n",
    "\n",
    "linear_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22e29a3c-12c6-4f06-a015-025a3d9542fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:modeling.models.sklearn_pipeline.model:Estimator of type <class 'sklearn.linear_model._coordinate_descent.ElasticNet'> does not have `feature_importances_` using sklearn.inspection.permutation_importances instead.\n",
      "INFO:modeling.models.sklearn_pipeline.model:`Using model-agnostic` <class 'shap.explainers._exact.ExactExplainer'>` to extract SHAP values... `shap` can't apply model-specific algorithms for <class 'modeling.models.sklearn_pipeline.model.SklearnPipeline'>. Consider switching to `SklearnModel` if computation time or quality don't fit your needs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ExactExplainer explainer: 1176it [00:13, 36.47it/s]                                                                     \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default_importance</th>\n",
       "      <th>shap_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iron_feed</th>\n",
       "      <td>-0.000075</td>\n",
       "      <td>0.011944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silica_feed</th>\n",
       "      <td>0.049934</td>\n",
       "      <td>0.427674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feed_diff_divide_silica</th>\n",
       "      <td>0.187737</td>\n",
       "      <td>0.786483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         default_importance  shap_importance\n",
       "iron_feed                         -0.000075         0.011944\n",
       "silica_feed                        0.049934         0.427674\n",
       "feed_diff_divide_silica            0.187737         0.786483"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_importance = linear_pipeline.get_feature_importance(\n",
    "    train_data,\n",
    ")\n",
    "shap_importance = linear_pipeline.get_shap_feature_importance(\n",
    "    train_data[linear_pipeline.features_in],\n",
    ")\n",
    "linear_importance_table = pd.DataFrame(\n",
    "    {\n",
    "        \"default_importance\": default_importance,\n",
    "        \"shap_importance\": shap_importance,\n",
    "    }\n",
    ")\n",
    "linear_importance_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f634117-70fd-499c-b49c-837db8236405",
   "metadata": {},
   "source": [
    "### Nearest neighbor regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429296ed-b1dd-47af-8dde-66fd954065a3",
   "metadata": {},
   "source": [
    "Here we will repeat the procedure using a KNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9045e4f8-5b8a-472b-99d8-6b9ba5a1753f",
   "metadata": {},
   "source": [
    "#### Pipeline inicialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ad5818b-363e-4c97-ae53-2d7668f8744d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SklearnPipeline(estimator=Pipeline(steps=[('standard_scaler',\n",
       "                 SklearnTransform(transformer=StandardScaler())),\n",
       "                ('estimator', KNeighborsRegressor())]), target=\"silica_conc\" ,features_in=['iron_feed', 'silica_feed', 'feed_diff_divide_silica'], features_out=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_pipeline_init_config = {\n",
    "    'estimator': {\n",
    "        'class_name': 'sklearn.neighbors.KNeighborsRegressor',\n",
    "        'kwargs': {\n",
    "        }\n",
    "    },\n",
    "    'transformers': [\n",
    "        {\n",
    "            'class_name': 'sklearn.preprocessing.StandardScaler',\n",
    "            'kwargs': {},\n",
    "            'name': 'standard_scaler',\n",
    "            'wrapper': 'preserve_columns',\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "knn_pipeline_factory = create_model_factory(\n",
    "    model_factory_type=\"modeling.SklearnPipelineFactory\",\n",
    "    model_init_config=knn_pipeline_init_config,\n",
    "    features=model_features,\n",
    "    target=target_column,\n",
    ")\n",
    "\n",
    "knn_pipeline = knn_pipeline_factory.create()\n",
    "knn_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0e4e86-c69c-47fc-a221-8c5459ebb390",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1446ed97-bf00-4a98-8956-7cd93e5284f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:modeling.models.sklearn_pipeline.model:`features_out` attribute is not specified. Setting `features_out` based on factual data.\n",
      "INFO:modeling.models.sklearn_pipeline.tuner:Initializing sklearn hyperparameters tuner...\n",
      "INFO:modeling.models.sklearn_pipeline.tuner:Tuning hyperparameters...\n",
      "The best params:\n",
      "\n",
      "algorithm: kd_tree\n",
      "leaf_size: 30\n",
      "metric: minkowski\n",
      "metric_params: None\n",
      "n_jobs: None\n",
      "n_neighbors: 30\n",
      "p: 2\n",
      "weights: distance\n"
     ]
    }
   ],
   "source": [
    "knn_pipeline_tuner_config = {\n",
    "    'class_name': 'sklearn.model_selection.GridSearchCV',\n",
    "    'kwargs': {\n",
    "        'n_jobs': -1,\n",
    "        'refit': 'mae',\n",
    "        'param_grid': {\n",
    "            'estimator__weights': ['uniform', 'distance'],\n",
    "            'estimator__algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
    "            'estimator__n_neighbors': [10, 20, 30, 40],\n",
    "        },\n",
    "        'scoring': {\n",
    "            'mae': 'neg_mean_absolute_error',\n",
    "            'rmse': 'neg_root_mean_squared_error',\n",
    "            'r2': 'r2',\n",
    "        },\n",
    "        'cv': 5,\n",
    "    }\n",
    "}\n",
    "\n",
    "knn_pipeline_tuner = create_tuner(\n",
    "    model_factory=knn_pipeline_factory,\n",
    "    model_tuner_type=\"modeling.SklearnPipelineTuner\",\n",
    "    tuner_config=knn_pipeline_tuner_config,\n",
    ")\n",
    "\n",
    "knn_pipeline = tune_model(\n",
    "    model_tuner=knn_pipeline_tuner,\n",
    "    data=train_data,\n",
    "    hyperparameters_config=None,\n",
    ")\n",
    "\n",
    "print(\"The best params:\\n\")\n",
    "for k, v in knn_pipeline.estimator.get_params().items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bc33f0-d7bc-42b8-9a7a-9076c9464090",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53c210b2-41ad-41dc-bfb5-55b5393f6137",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipeline = train_model(knn_pipeline, train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2264956-81c5-46ad-bb9e-3dbf3e4ca908",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "380e59f2-337b-440a-82e9-01f9d9f065c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_metric_value</th>\n",
       "      <th>test_metric_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>1.243789</td>\n",
       "      <td>2.829170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>2.130970</td>\n",
       "      <td>3.566096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse</th>\n",
       "      <td>4.541032</td>\n",
       "      <td>12.717039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mape</th>\n",
       "      <td>0.098479</td>\n",
       "      <td>0.230056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_squared</th>\n",
       "      <td>0.571305</td>\n",
       "      <td>-0.487937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_score</th>\n",
       "      <td>0.571997</td>\n",
       "      <td>-0.484464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             train_metric_value  test_metric_value\n",
       "metric_name                                       \n",
       "mae                    1.243789           2.829170\n",
       "rmse                   2.130970           3.566096\n",
       "mse                    4.541032          12.717039\n",
       "mape                   0.098479           0.230056\n",
       "r_squared              0.571305          -0.487937\n",
       "var_score              0.571997          -0.484464"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_metrics = calculate_metrics(\n",
    "    train_data, model=knn_pipeline,\n",
    ")\n",
    "\n",
    "test_metrics = calculate_metrics(\n",
    "    test_data, model=knn_pipeline,\n",
    ")\n",
    "\n",
    "knn_metrics = pd.DataFrame(\n",
    "    {\n",
    "        \"train_metric_value\": train_metrics,\n",
    "        \"test_metric_value\": test_metrics,\n",
    "    },\n",
    ").rename_axis(\"metric_name\")\n",
    "\n",
    "knn_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af8bc5fb-8e34-4b4d-9b2f-e3d93e6c7354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:modeling.models.sklearn_pipeline.model:Estimator of type <class 'sklearn.neighbors._regression.KNeighborsRegressor'> does not have `feature_importances_` using sklearn.inspection.permutation_importances instead.\n",
      "INFO:modeling.models.sklearn_pipeline.model:`Using model-agnostic` <class 'shap.explainers._exact.ExactExplainer'>` to extract SHAP values... `shap` can't apply model-specific algorithms for <class 'modeling.models.sklearn_pipeline.model.SklearnPipeline'>. Consider switching to `SklearnModel` if computation time or quality don't fit your needs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ExactExplainer explainer: 1176it [00:17, 28.43it/s]                                                                     \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default_importance</th>\n",
       "      <th>shap_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iron_feed</th>\n",
       "      <td>0.640723</td>\n",
       "      <td>0.662018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silica_feed</th>\n",
       "      <td>0.607175</td>\n",
       "      <td>0.564240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feed_diff_divide_silica</th>\n",
       "      <td>0.638325</td>\n",
       "      <td>0.653207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         default_importance  shap_importance\n",
       "iron_feed                          0.640723         0.662018\n",
       "silica_feed                        0.607175         0.564240\n",
       "feed_diff_divide_silica            0.638325         0.653207"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_importance = knn_pipeline.get_feature_importance(\n",
    "    train_data,\n",
    ")\n",
    "shap_importance = knn_pipeline.get_shap_feature_importance(\n",
    "    train_data[knn_pipeline.features_in],\n",
    ")\n",
    "knn_importance_table = pd.DataFrame(\n",
    "    {\n",
    "        \"default_importance\": default_importance,\n",
    "        \"shap_importance\": shap_importance,\n",
    "    }\n",
    ")\n",
    "knn_importance_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c4639f-7659-46b7-9699-7d651ffe585d",
   "metadata": {},
   "source": [
    "## Model validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d4578d-8246-4873-a018-499051aebb47",
   "metadata": {},
   "source": [
    "We will showcase the validation approach with the linear model. As it is the preferred approach for baselining and its metrics on the test set are better than the KNN approach, it is better baseline candidate. To do so, we need to perform two checks:\n",
    "\n",
    "* Model errors have an average of 0.\n",
    "* Uplifts found through interventions are not caused by the model error.\n",
    "\n",
    "Checks need to be performed over a subset of data that has not been used for training, to mimic the live behaviour of the model. It also needs to be a historical period where no interventions have been made. Because of that, the errors of the test set are a good candidate for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10adebea-03b2-410d-bded-52b93202e1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling import calculate_model_predictions\n",
    "\n",
    "linear_test_predictions = calculate_model_predictions(\n",
    "    test_data, linear_pipeline,\n",
    ")\n",
    "model_errors = test_data[target_column] - linear_test_predictions[\"model_prediction\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fef88d-180c-4426-875d-a05d53795f77",
   "metadata": {},
   "source": [
    "### Average model error is 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3e5ca2-7d3f-47c1-8a83-d953f8706b4a",
   "metadata": {},
   "source": [
    "To check whether the average model error is consistent with 0, we will perform hypothesis testing with the following hypothesis:\n",
    "\n",
    "* H0: Model errors have an average of 0.\n",
    "* H1: Model errors have an average different than 0.\n",
    "\n",
    "Here, we will assume that the model error distribution is such that a T-test can be applied. This is a reasonable assumption every time that the sample size is greater than 30. If it is not the case, other techniquest to perform hypothesis testing, such as bootstrapping, can be explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45ad9126-2a22-4b49-8ab8-72fd73dc2679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_errors.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95db7aa7-d15c-4a18-abe0-dbf247412212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=0.16782919502110405, pvalue=0.8670230527053208, df=111)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "ttest_1samp(model_errors, popmean=0, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a37fe4-97f4-46b7-bdd5-c3c1b4e6720b",
   "metadata": {},
   "source": [
    "P-value is not big enough, so we do not have the evidence to reject the null hypothesis (model errors are 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0240aad7-d0f3-44b8-8e67-493b08b9d6bb",
   "metadata": {},
   "source": [
    "### Minimum intervention average value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f455d48-c8e6-4421-bed1-57b497fd592b",
   "metadata": {},
   "source": [
    "Now, we wish to check if we are able to capture the expected uplift from our interventions using this baseline model.\n",
    "\n",
    "To do so, we perform a hypothesis test with the following hypothesis:\n",
    "\n",
    "* H0: Uplift and model error have the same mean.\n",
    "* H1: Uplift has a greater (or smaller, depending on the use case) mean than the model error.\n",
    "\n",
    "We will assume that the uplifts mean is expected to be smaller than the model error. Again, we will use a T-test because our sample size is big enough. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08f9a757-0367-4a5f-89c2-d80b7464308c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_after_oai.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e6b0d45-05e5-4f65-8c81-c3af1f09d452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8041783222535256"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_oai_predictions = calculate_model_predictions(\n",
    "    df_after_oai, linear_pipeline,\n",
    ")\n",
    "uplift = df_after_oai[target_column] - after_oai_predictions[\"model_prediction\"]\n",
    "uplift.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cc71a29-61d0-472f-a1e1-8ac70bd86d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-1.7525977362331289, pvalue=0.040824768181986215, df=154.90741383442028)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "ttest_ind(uplift, model_errors, equal_var=False, alternative='less')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4707c0-3420-455b-a108-1beff30a8d4d",
   "metadata": {},
   "source": [
    "As the p-value is smaller than 0.05, which is the usuall threshold to reject the null hypothesys, we reject that the uplifts and the model errors have the same mean in favour of the uplifts having a smaller mean than the model errors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
